{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGj9jQjjGG1J",
        "outputId": "4eafa6d3-118a-4a58-9d7c-a7a557c051c3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# Check this site for the latest download link\n",
        "# https://www.apache.org/dyn/closer.lua/spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YyD72jVGNws",
        "outputId": "9b75da7c-f78e-4536-83b1-d19745886d53"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.83)] [\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\u001b[33m\r0% [2 InRelease 15.6 kB/128 kB 12%] [Waiting for headers] [Connected to cloud.r\u001b[0m\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\u001b[33m\r0% [2 InRelease 15.6 kB/128 kB 12%] [Waiting for headers] [Connected to cloud.r\u001b[0m\u001b[33m\r0% [2 InRelease 24.3 kB/128 kB 19%] [Waiting for headers] [Connected to cloud.r\u001b[0m\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [2 InRelease 47.5 kB/128 kB 37%] [Waiting for headers] [Waiting for headers]\u001b[0m\r                                                                               \rGet:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,107 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [59.5 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,446 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,672 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,452 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,610 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,319 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,163 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,391 kB]\n",
            "Fetched 23.6 MB in 5s (5,197 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "59 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.5.2-bin-hadoop3.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "# Create Spark Session in localhost\n",
        "spark = SparkSession.builder.master(\"local\").\\\n",
        "    appName(\"ITESO-DecisionTree\").\\\n",
        "    getOrCreate()\n",
        "\n",
        "# Set spark context\n",
        "sc = spark.sparkContext\n",
        "sc.setLogLevel(\"ERROR\")\n",
        "\n",
        "iris_df = spark.read.format(\"csv\").\\\n",
        "    option(\"header\", \"true\").\\\n",
        "    option(\"mode\", \"permissive\").\\\n",
        "    option(\"path\", \"/content/drive/MyDrive/Colab Notebooks (1)/datasets/iris_dataset.csv\").\\\n",
        "    load()\n",
        "iris_df.show(n=10, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTYFcprIGOKc",
        "outputId": "ff746fcc-3ec1-488b-f594-36c415526fb4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "|Id |SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|Species    |\n",
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "|1  |5.1          |3.5         |1.4          |0.2         |Iris-setosa|\n",
            "|2  |4.9          |3.0         |1.4          |0.2         |Iris-setosa|\n",
            "|3  |4.7          |3.2         |1.3          |0.2         |Iris-setosa|\n",
            "|4  |4.6          |3.1         |1.5          |0.2         |Iris-setosa|\n",
            "|5  |5.0          |3.6         |1.4          |0.2         |Iris-setosa|\n",
            "|6  |5.4          |3.9         |1.7          |0.4         |Iris-setosa|\n",
            "|7  |4.6          |3.4         |1.4          |0.3         |Iris-setosa|\n",
            "|8  |5.0          |3.4         |1.5          |0.2         |Iris-setosa|\n",
            "|9  |4.4          |2.9         |1.4          |0.2         |Iris-setosa|\n",
            "|10 |4.9          |3.1         |1.5          |0.1         |Iris-setosa|\n",
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
        "# Create a small dataset as a list of tuples\n",
        "# Format: (label, feature1, feature2)\n",
        "# Create data frame\n",
        "columns = [\"Id\",\"SepalLengthCm\",\"SepalWidthCm\",\"PetalLengthCm\",\"PetalWidthCm\",\"Species\"]\n",
        "# Assemble the features into a single vector column\n",
        "\n",
        "\n",
        "iris_df = iris_df.withColumn(\"SepalLengthCm\", col(\"SepalLengthCm\").cast(\"float\")) \\\n",
        "                 .withColumn(\"SepalWidthCm\", col(\"SepalWidthCm\").cast(\"float\")) \\\n",
        "                 .withColumn(\"PetalLengthCm\", col(\"PetalLengthCm\").cast(\"float\")) \\\n",
        "                 .withColumn(\"PetalWidthCm\", col(\"PetalWidthCm\").cast(\"float\")) \\\n",
        "                 .withColumn(\"Id\", col(\"Id\").cast(\"float\"))\n",
        "#label_indexer = StringIndexer(inputCol= \"Id\", outputCol=\"label\")\n",
        "species_indexer = StringIndexer(inputCol=\"Species\", outputCol=\"label\")\n",
        "\n",
        "iris_df = species_indexer.fit(iris_df).transform(iris_df)\n",
        "\n",
        "assembler = VectorAssembler(inputCols=[\"Id\",\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"],\n",
        "outputCol=\"features\")\n",
        "data_with_features = assembler.transform(iris_df).select(\"label\", \"features\")\n",
        "# Split the data: 80% training data and 20% testing data\n",
        "train, test = data_with_features.randomSplit([0.8, 0.2], seed=13)"
      ],
      "metadata": {
        "id": "-U9WIOg8Ivqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the Decision Tree model\n",
        "dt = DecisionTreeClassifier(labelCol=\"label\",\n",
        "featuresCol=\"features\")\n",
        "# ============================\n",
        "# TRAIN\n",
        "# ============================\n",
        "# Train to get the model\n",
        "dt_model = dt.fit(train)\n",
        "\n",
        "\n",
        "# Use the trained model to make predictions on the test data\n",
        "predictions = dt_model.transform(test)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\",\n",
        "predictionCol=\"prediction\")\n",
        "\n",
        "\n",
        "# Initialize the LinearSVC classifier for binary\n",
        "# classification\n",
        "lsvc = LinearSVC(maxIter=10, regParam=0.01)\n",
        "\n",
        "# Set up OneVsRest classifier for multi-class\n",
        "# classification\n",
        "ovr = OneVsRest(classifier=lsvc)\n",
        "\n",
        "# ============================\n",
        "# TRAIN\n",
        "# ============================\n",
        "\n",
        "# Train the model\n",
        "ovr_model = ovr.fit(train)\n",
        "\n",
        "# Use the trained model to make predictions on the test data\n",
        "predictions = ovr_model.transform(test)\n",
        "\n",
        "# Show predictions\n",
        "predictions.show()\n",
        "\n",
        "f1 = evaluator.evaluate(predictions,\n",
        "{evaluator.metricName: \"f1\"})\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67iCrTCvGWH1",
        "outputId": "43eeff50-e87f-424d-ac96-6bb3fa41d9dc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree model summary:DecisionTreeClassificationModel: uid=DecisionTreeClassifier_b2078394896c, depth=3, numNodes=7, numClasses=3, numFeatures=5\n",
            "  If (feature 3 <= 2.449999988079071)\n",
            "   Predict: 0.0\n",
            "  Else (feature 3 > 2.449999988079071)\n",
            "   If (feature 0 <= 98.5)\n",
            "    Predict: 1.0\n",
            "   Else (feature 0 > 98.5)\n",
            "    If (feature 3 <= 4.25)\n",
            "     Predict: 1.0\n",
            "    Else (feature 3 > 4.25)\n",
            "     Predict: 2.0\n",
            "\n",
            "Accuracy: 1.0\n",
            "Precision: 0.9999999999999999\n",
            "Recall: 0.9999999999999999\n",
            "F1 Score: 0.9999999999999999\n",
            "+-----+--------------------+--------------------+----------+\n",
            "|label|            features|       rawPrediction|prediction|\n",
            "+-----+--------------------+--------------------+----------+\n",
            "|  0.0|[2.0,4.9000000953...|[1.56524332417723...|       0.0|\n",
            "|  0.0|[6.0,5.4000000953...|[1.95752551987567...|       0.0|\n",
            "|  0.0|[13.0,4.800000190...|[1.62183583384842...|       0.0|\n",
            "|  0.0|[24.0,5.099999904...|[1.22020153908342...|       0.0|\n",
            "|  0.0|[25.0,4.800000190...|[1.59564601655131...|       0.0|\n",
            "|  0.0|[27.0,5.0,3.40000...|[1.45932855982669...|       0.0|\n",
            "|  0.0|[28.0,5.199999809...|[1.78644986365974...|       0.0|\n",
            "|  0.0|[31.0,4.800000190...|[1.40779473974129...|       0.0|\n",
            "|  0.0|[39.0,4.400000095...|[1.43984502553602...|       0.0|\n",
            "|  0.0|[48.0,4.599999904...|[1.50232393331878...|       0.0|\n",
            "|  1.0|[68.0,5.800000190...|[-1.2430536035002...|       1.0|\n",
            "|  1.0|[69.0,6.199999809...|[-2.4834702882505...|       1.0|\n",
            "|  1.0|[71.0,5.900000095...|[-2.0020448759086...|       1.0|\n",
            "|  1.0|[75.0,6.400000095...|[-1.5947033570795...|       1.0|\n",
            "|  1.0|[82.0,5.5,2.40000...|[-1.4021871694025...|       1.0|\n",
            "|  1.0|[93.0,5.800000190...|[-1.6714000477513...|       1.0|\n",
            "|  1.0|[94.0,5.0,2.29999...|[-1.3410980545254...|       1.0|\n",
            "|  2.0|[104.0,6.30000019...|[-2.8611016962840...|       2.0|\n",
            "|  2.0|[113.0,6.80000019...|[-3.1802190447771...|       2.0|\n",
            "|  2.0|[116.0,6.40000009...|[-3.1077013884103...|       2.0|\n",
            "+-----+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "F1 Score: 0.9999999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0HGnWo0XHO1S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
