{
  "cells": [
    {
      "metadata": {
        "id": "e8fdfd13e7871482",
        "outputId": "78d0dd4a-0f2f-465e-82b3-f4c42f31e97f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "execution_count": 2,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "e8fdfd13e7871482"
    },
    {
      "metadata": {
        "id": "c8b79a0cb8247454",
        "outputId": "6f6ebcd7-9e73-4d16-c7fc-7a37a08f1bd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [59.5 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,107 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,610 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,391 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,446 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,163 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,319 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,672 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,452 kB]\n",
            "Fetched 23.6 MB in 3s (8,909 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "59 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.5.2-bin-hadoop3.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "execution_count": 3,
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# Check this site for the latest download link\n",
        "# https://www.apache.org/dyn/closer.lua/spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j"
      ],
      "id": "c8b79a0cb8247454"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Required Libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, FloatType, StringType, IntegerType\n",
        "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "            .appName(\"SVM\") \\\n",
        "            .config(\"spark.ui.port\", \"4040\") \\\n",
        "            .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"ERROR\")\n",
        "\n",
        "# Define the schema of the iris dataset\n",
        "iris_schema = StructType([\n",
        "    StructField(\"Id\", FloatType(), True),\n",
        "    StructField(\"SepalLengthCm\", FloatType(), True),\n",
        "    StructField(\"SepalWidthCm\", FloatType(), True),\n",
        "    StructField(\"PetalLengthCm\", FloatType(), True),\n",
        "    StructField(\"PetalWidthCm\", FloatType(), True),\n",
        "    StructField(\"Species\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Load the iris dataset from Google Drive\n",
        "iris_df = spark.read.format(\"csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .option(\"mode\", \"permissive\") \\\n",
        "    .schema(iris_schema) \\\n",
        "    .load(\"/content/drive/MyDrive/ColabNotebooks/datasets/Iris.csv\")"
      ],
      "metadata": {
        "id": "wtaMTA2A82Mj"
      },
      "id": "wtaMTA2A82Mj",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the unique values in the Species column\n",
        "iris_df.select(\"Species\").distinct().show()\n",
        "\n",
        "# Adjust the mapping based on actual species names\n",
        "df_with_numeric_species = iris_df.withColumn(\n",
        "    \"Species\",\n",
        "    when(iris_df[\"Species\"] == \"Iris-setosa\", 0)\n",
        "    .when(iris_df[\"Species\"] == \"Iris-versicolor\", 1)\n",
        "    .when(iris_df[\"Species\"] == \"Iris-virginica\", 2)\n",
        "    .otherwise(None)\n",
        ")"
      ],
      "metadata": {
        "id": "tLSyLL9EA3-H",
        "outputId": "50e88978-65f3-411b-87fe-27724825467a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tLSyLL9EA3-H",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|        Species|\n",
            "+---------------+\n",
            "| Iris-virginica|\n",
            "|    Iris-setosa|\n",
            "|Iris-versicolor|\n",
            "+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_numeric_species = df_with_numeric_species.na.drop(subset=[\"Species\"])\n",
        "\n",
        "df_with_numeric_species = df_with_numeric_species.withColumn(\"Species\", df_with_numeric_species[\"Species\"].cast(IntegerType()))\n",
        "\n",
        "# Vectorize Features\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "df_with_features = assembler.transform(df_with_numeric_species).select(\"features\", \"Species\")\n",
        "\n",
        "df_with_features = df_with_features.withColumnRenamed(\"Species\", \"label\")"
      ],
      "metadata": {
        "id": "UrsXOeCzA48L"
      },
      "id": "UrsXOeCzA48L",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Initialize and Train Model\n",
        "lsvc = LinearSVC(maxIter=10, regParam=0.01)\n",
        "\n",
        "# Set up OneVsRest for multi-class classification\n",
        "ovr = OneVsRest(classifier=lsvc)\n",
        "\n",
        "# Train the model\n",
        "ovr_model = ovr.fit(df_with_features)"
      ],
      "metadata": {
        "id": "p7G4xAOFBCEA"
      },
      "id": "p7G4xAOFBCEA",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Evaluate the Model\n",
        "predictions = ovr_model.transform(df_with_features)\n",
        "\n",
        "# Use MulticlassClassificationEvaluator with f1 metric\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\"\n",
        ")\n",
        "f1_score = evaluator.evaluate(predictions)"
      ],
      "metadata": {
        "id": "f0RKAVpIBG4J"
      },
      "id": "f0RKAVpIBG4J",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display F1 score\n",
        "print(f\"F1 Score: {f1_score}\")"
      ],
      "metadata": {
        "id": "6tU5Bv7xBJSQ",
        "outputId": "80d9fe2f-5c2d-42f1-c469-45886b4c21fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6tU5Bv7xBJSQ",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.920045695045695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop the Spark session\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "xO8SY4q0BJ45"
      },
      "id": "xO8SY4q0BJ45",
      "execution_count": 21,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}