{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcamarillor/O2024_ESI3914O/blob/pablo_camarillo_lecture_10/examples/notebooks/columns_operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPSQzDhW0nKI",
        "outputId": "235b93d4-2be5-4af5-ffaa-a41f40b138ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,149 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,224 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [999 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,571 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,298 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [27.8 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,499 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,438 kB]\n",
            "Fetched 19.5 MB in 8s (2,588 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "51 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=9faac3fbd3dada36b3f68b5da9b6e5f9f2b8a168bda48b1bd31b8aee6b25b38e\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# Check this site for the latest download link\n",
        "# https://www.apache.org/dyn/closer.lua/spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "c8RNY4wS0iKl",
        "outputId": "bd47d8f5-073c-4008-c40c-71240503137a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+--------+--------+----------+---------+--------------+\n",
            "|order_id|   product| price|quantity|discount|first_name|last_name|order_date_str|\n",
            "+--------+----------+------+--------+--------+----------+---------+--------------+\n",
            "|       1|    Laptop|1200.0|       1|   100.0|      John|      Doe|    2024-09-01|\n",
            "|       2|Smartphone| 800.0|       2|    50.0|      Jane|    Smith|    09/02/2024|\n",
            "|       3|Headphones| 200.0|       3|    20.0|     Alice|    Brown|    2024-09-03|\n",
            "|       4|   Monitor| 300.0|       2|    30.0|       Bob|  Johnson|    09/04/2024|\n",
            "|       5|  Keyboard| 100.0|       5|    10.0|       Eve| Williams|    2024-09-05|\n",
            "+--------+----------+------+--------+--------+----------+---------+--------------+\n",
            "\n",
            "root\n",
            " |-- order_id: integer (nullable = false)\n",
            " |-- product: string (nullable = false)\n",
            " |-- price: float (nullable = false)\n",
            " |-- quantity: integer (nullable = false)\n",
            " |-- discount: float (nullable = true)\n",
            " |-- first_name: string (nullable = false)\n",
            " |-- last_name: string (nullable = false)\n",
            " |-- order_date_str: string (nullable = false)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import to_date, when, col\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"E-Commerce App DataFrame with Mixed Date Formats\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Define the schema (excluding order_date, it will be derived from order_date_str)\n",
        "schema = StructType([\n",
        "    StructField(\"order_id\", IntegerType(), nullable=False),\n",
        "    StructField(\"product\", StringType(), nullable=False),\n",
        "    StructField(\"price\", FloatType(), nullable=False),\n",
        "    StructField(\"quantity\", IntegerType(), nullable=False),\n",
        "    StructField(\"discount\", FloatType(), nullable=True),\n",
        "    StructField(\"first_name\", StringType(), nullable=False),\n",
        "    StructField(\"last_name\", StringType(), nullable=False),\n",
        "    StructField(\"order_date_str\", StringType(), nullable=False)  # String date with mixed formats\n",
        "])\n",
        "\n",
        "# Sample data with mixed date formats in 'order_date_str'\n",
        "data = [\n",
        "    Row(order_id=1, product=\"Laptop\", price=1200.00, quantity=1, discount=100.00, first_name=\"John\", last_name=\"Doe\", order_date_str=\"2024-09-01\"),\n",
        "    Row(order_id=2, product=\"Smartphone\", price=800.00, quantity=2, discount=50.00, first_name=\"Jane\", last_name=\"Smith\", order_date_str=\"09/02/2024\"),\n",
        "    Row(order_id=3, product=\"Headphones\", price=200.00, quantity=3, discount=20.00, first_name=\"Alice\", last_name=\"Brown\", order_date_str=\"2024-09-03\"),\n",
        "    Row(order_id=4, product=\"Monitor\", price=300.00, quantity=2, discount=30.00, first_name=\"Bob\", last_name=\"Johnson\", order_date_str=\"09/04/2024\"),\n",
        "    Row(order_id=5, product=\"Keyboard\", price=100.00, quantity=5, discount=10.00, first_name=\"Eve\", last_name=\"Williams\", order_date_str=\"2024-09-05\")\n",
        "]\n",
        "\n",
        "# Create the DataFrame\n",
        "df = spark.createDataFrame(data, schema)\n",
        "\n",
        "# Show the updated DataFrame with the correct 'order_date' column\n",
        "df.show()\n",
        "\n",
        "# Print the schema to verify the new 'order_date' column is of DateType\n",
        "df.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit\n",
        "df = df.withColumn(\"new_column\", lit(10))\n",
        "df.show()"
      ],
      "metadata": {
        "id": "ISP8tFoMM-89",
        "outputId": "33521e19-f2e7-4213-95e6-5b51c314bd3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+--------+--------+----------+---------+--------------+----------+\n",
            "|order_id|   product| price|quantity|discount|first_name|last_name|order_date_str|new_column|\n",
            "+--------+----------+------+--------+--------+----------+---------+--------------+----------+\n",
            "|       1|    Laptop|1200.0|       1|   100.0|      John|      Doe|    2024-09-01|        10|\n",
            "|       2|Smartphone| 800.0|       2|    50.0|      Jane|    Smith|    09/02/2024|        10|\n",
            "|       3|Headphones| 200.0|       3|    20.0|     Alice|    Brown|    2024-09-03|        10|\n",
            "|       4|   Monitor| 300.0|       2|    30.0|       Bob|  Johnson|    09/04/2024|        10|\n",
            "|       5|  Keyboard| 100.0|       5|    10.0|       Eve| Williams|    2024-09-05|        10|\n",
            "+--------+----------+------+--------+--------+----------+---------+--------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(\"new_column\")\n",
        "df = df.withColumn('total_cost', \\\n",
        "      df['price'] * df['quantity'])\n",
        "df.show()"
      ],
      "metadata": {
        "id": "SGlLnUi9OXS9",
        "outputId": "9d76585c-8b22-481c-c528-10ea13ba85f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+--------+--------+----------+---------+--------------+----------+\n",
            "|order_id|   product| price|quantity|discount|first_name|last_name|order_date_str|total_cost|\n",
            "+--------+----------+------+--------+--------+----------+---------+--------------+----------+\n",
            "|       1|    Laptop|1200.0|       1|   100.0|      John|      Doe|    2024-09-01|    1200.0|\n",
            "|       2|Smartphone| 800.0|       2|    50.0|      Jane|    Smith|    09/02/2024|    1600.0|\n",
            "|       3|Headphones| 200.0|       3|    20.0|     Alice|    Brown|    2024-09-03|     600.0|\n",
            "|       4|   Monitor| 300.0|       2|    30.0|       Bob|  Johnson|    09/04/2024|     600.0|\n",
            "|       5|  Keyboard| 100.0|       5|    10.0|       Eve| Williams|    2024-09-05|     500.0|\n",
            "+--------+----------+------+--------+--------+----------+---------+--------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"final_price\", df['total_cost'] - df['discount'])\n",
        "df.show()"
      ],
      "metadata": {
        "id": "MsdDRS-zO3dd",
        "outputId": "1e773ea6-e181-455d-f566-95de30dd1b3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+--------+--------+----------+---------+--------------+----------+-----------+\n",
            "|order_id|   product| price|quantity|discount|first_name|last_name|order_date_str|total_cost|final_price|\n",
            "+--------+----------+------+--------+--------+----------+---------+--------------+----------+-----------+\n",
            "|       1|    Laptop|1200.0|       1|   100.0|      John|      Doe|    2024-09-01|    1200.0|     1100.0|\n",
            "|       2|Smartphone| 800.0|       2|    50.0|      Jane|    Smith|    09/02/2024|    1600.0|     1550.0|\n",
            "|       3|Headphones| 200.0|       3|    20.0|     Alice|    Brown|    2024-09-03|     600.0|      580.0|\n",
            "|       4|   Monitor| 300.0|       2|    30.0|       Bob|  Johnson|    09/04/2024|     600.0|      570.0|\n",
            "|       5|  Keyboard| 100.0|       5|    10.0|       Eve| Williams|    2024-09-05|     500.0|      490.0|\n",
            "+--------+----------+------+--------+--------+----------+---------+--------------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "df = df.withColumn('is_high_value', when(df['final_price'] > 1000, \"YES\").otherwise(\"NO\"))"
      ],
      "metadata": {
        "id": "E-nWqPAZP_mI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "lHMCx7hfQGv0",
        "outputId": "275ba05e-1e90-4afd-cf56-936beda5f19e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+--------+--------+----------+---------+--------------+----------+-----------+-------------+\n",
            "|order_id|   product| price|quantity|discount|first_name|last_name|order_date_str|total_cost|final_price|is_high_value|\n",
            "+--------+----------+------+--------+--------+----------+---------+--------------+----------+-----------+-------------+\n",
            "|       1|    Laptop|1200.0|       1|   100.0|      John|      Doe|    2024-09-01|    1200.0|     1100.0|          YES|\n",
            "|       2|Smartphone| 800.0|       2|    50.0|      Jane|    Smith|    09/02/2024|    1600.0|     1550.0|          YES|\n",
            "|       3|Headphones| 200.0|       3|    20.0|     Alice|    Brown|    2024-09-03|     600.0|      580.0|           NO|\n",
            "|       4|   Monitor| 300.0|       2|    30.0|       Bob|  Johnson|    09/04/2024|     600.0|      570.0|           NO|\n",
            "|       5|  Keyboard| 100.0|       5|    10.0|       Eve| Williams|    2024-09-05|     500.0|      490.0|           NO|\n",
            "+--------+----------+------+--------+--------+----------+---------+--------------+----------+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import concat\n",
        "\n",
        "df = df.withColumn('full_name', concat(df['first_name'], lit(' '), df['last_name']))\n",
        "df_reduced = df.select(\"first_name\", \"last_name\", \"full_name\")\n",
        "df_reduced.show()"
      ],
      "metadata": {
        "id": "voTph1dCQ3XZ",
        "outputId": "0cfc5553-3459-462d-d1d5-2c21a5494f9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+------------+\n",
            "|first_name|last_name|   full_name|\n",
            "+----------+---------+------------+\n",
            "|      John|      Doe|    John Doe|\n",
            "|      Jane|    Smith|  Jane Smith|\n",
            "|     Alice|    Brown| Alice Brown|\n",
            "|       Bob|  Johnson| Bob Johnson|\n",
            "|       Eve| Williams|Eve Williams|\n",
            "+----------+---------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('order_date',\n",
        "    when(col('order_date_str').rlike(\"^\\d{4}-\\d{2}-\\d{2}$\"), to_date(col('order_date_str'), 'yyyy-MM-dd'))\n",
        "    .when(col('order_date_str').rlike(\"^\\d{2}/\\d{2}/\\d{4}$\"), to_date(col('order_date_str'), 'MM/dd/yyyy'))\n",
        "    .otherwise(None)  # Handle unexpected formats with None\n",
        ")\n",
        "df.select(\"order_id\", \"product\", \"order_date_str\", \"order_date\").show()"
      ],
      "metadata": {
        "id": "_TVNNxL7XAxp",
        "outputId": "8ba419d5-85ec-466d-f042-b9fabb0db4e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+--------------+----------+\n",
            "|order_id|   product|order_date_str|order_date|\n",
            "+--------+----------+--------------+----------+\n",
            "|       1|    Laptop|    2024-09-01|2024-09-01|\n",
            "|       2|Smartphone|    09/02/2024|2024-09-02|\n",
            "|       3|Headphones|    2024-09-03|2024-09-03|\n",
            "|       4|   Monitor|    09/04/2024|2024-09-04|\n",
            "|       5|  Keyboard|    2024-09-05|2024-09-05|\n",
            "+--------+----------+--------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import year, month\n",
        "\n",
        "df = df.withColumn('order_year', year(df['order_date']))\n",
        "df = df.withColumn('order_month', month(df['order_date']))"
      ],
      "metadata": {
        "id": "sQdrPtSWYx7t"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"order_id\", \"product\", \"order_year\", \"order_month\").show()"
      ],
      "metadata": {
        "id": "YQ-BNn0GYzLp",
        "outputId": "ab64f20d-ea83-4641-f3d3-07a5140a5b61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+----------+-----------+\n",
            "|order_id|   product|order_year|order_month|\n",
            "+--------+----------+----------+-----------+\n",
            "|       1|    Laptop|      2024|          9|\n",
            "|       2|Smartphone|      2024|          9|\n",
            "|       3|Headphones|      2024|          9|\n",
            "|       4|   Monitor|      2024|          9|\n",
            "|       5|  Keyboard|      2024|          9|\n",
            "+--------+----------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('price_int', df['price'].cast('integer'))\n",
        "df.select(\"order_id\", \"price\", \"price_int\").show()"
      ],
      "metadata": {
        "id": "8AU37qHMZcFo",
        "outputId": "4064c21f-fb7e-4e4b-e0de-195b6d7272f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+---------+\n",
            "|order_id| price|price_int|\n",
            "+--------+------+---------+\n",
            "|       1|1200.0|     1200|\n",
            "|       2| 800.0|      800|\n",
            "|       3| 200.0|      200|\n",
            "|       4| 300.0|      300|\n",
            "|       5| 100.0|      100|\n",
            "+--------+------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumnRenamed('price_int', 'price_integer')\n",
        "df.select(\"order_id\", \"price\", \"price_integer\").show()"
      ],
      "metadata": {
        "id": "dNwljg2RZzRZ",
        "outputId": "0fa79f6b-6cd6-4a3d-c042-8b4a9bec77c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+-------------+\n",
            "|order_id| price|price_integer|\n",
            "+--------+------+-------------+\n",
            "|       1|1200.0|         1200|\n",
            "|       2| 800.0|          800|\n",
            "|       3| 200.0|          200|\n",
            "|       4| 300.0|          300|\n",
            "|       5| 100.0|          100|\n",
            "+--------+------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "wHaBkB8YMAHz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}