{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!sudo apt update\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# Check this site for the latest download link\n",
    "# https://www.apache.org/dyn/closer.lua/spark\n",
    "!wget -q https://dlcdn.apache.org/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz\n",
    "!tar xf spark-3.5.2-bin-hadoop3.tgz\n",
    "!pip install -q findspark\n",
    "!pip install pyspark\n",
    "!pip install py4j"
   ],
   "id": "379feb0b88a93d3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import necessary modules\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import StructType, StructField, FloatType\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "            .appName(\"Decision-Trees-Example\") \\\n",
    "            .config(\"spark.ui.port\",\"4040\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Define the schema of the iris dataset if necessary\n",
    "iris_schema = StructType([\n",
    "    StructField(\"label\", FloatType(), True),\n",
    "    StructField(\"feature1\", FloatType(), True),\n",
    "    StructField(\"feature2\", FloatType(), True),\n",
    "    StructField(\"feature3\", FloatType(), True),\n",
    "    StructField(\"feature4\", FloatType(), True)\n",
    "])\n",
    "\n",
    "# Load the iris dataset from Google Drive\n",
    "iris_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"permissive\") \\\n",
    "    .schema(iris_schema) \\\n",
    "    .load(\"/content/drive/MyDrive/ColabNotebooks/datasets/iris.csv\")\n",
    "\n",
    "# Assemble the features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=[\"feature1\", \"feature2\", \"feature3\", \"feature4\"], outputCol=\"features\")\n",
    "data_with_features = assembler.transform(iris_df).select(\"label\", \"features\")\n",
    "\n",
    "# Split the data into training and test sets (80% training, 20% testing)\n",
    "train, test = data_with_features.randomSplit([0.8, 0.2], seed=13)\n",
    "\n",
    "# Show the dataset and training set\n",
    "print(\"Dataset\")\n",
    "data_with_features.show()\n",
    "\n",
    "print(\"Train set\")\n",
    "train.show()\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "# Train to get the model\n",
    "dt_model = dt.fit(train)\n",
    "\n",
    "# Display model summary\n",
    "print(\"Decision Tree model summary:\")\n",
    "print(dt_model.toDebugString)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "predictions = dt_model.transform(test)\n",
    "\n",
    "# Show predictions\n",
    "predictions.show()\n",
    "\n",
    "# Evaluate the model using MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})"
   ],
   "id": "96faff4e572f7e51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(f\"Accuracy: {accuracy}\")",
   "id": "57dbb59407093890"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(f\"Precision: {precision}\")",
   "id": "ad89255b48003ff3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(f\"Recall: {recall}\")",
   "id": "dc9e8a7ac8449173"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(f\"F1 Score: {f1}\")",
   "id": "30955c8260a05848"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Stop Spark session\n",
    "spark.stop()"
   ],
   "id": "9bb0fbf132d164c3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
