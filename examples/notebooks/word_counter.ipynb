{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcamarillor/O2024_ESI3914O/blob/pablo_camarillo_add_spark_setup/examples/notebooks/lab01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPSQzDhW0nKI",
        "outputId": "6bfe432e-7678-42d6-8232-0a25c3496a2b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\"sudo\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "El sistema no puede encontrar la ruta especificada.\n",
            "\"wget\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n",
            "tar: Error opening archive: Failed to open 'spark-3.5.2-bin-hadoop3.tgz'\n",
            "\n",
            "[notice] A new release of pip is available: 23.3.2 -> 24.2\n",
            "[notice] To update, run: C:\\Users\\avidr\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in c:\\users\\avidr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.5.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\avidr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyspark) (0.10.9.7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.2 -> 24.2\n",
            "[notice] To update, run: C:\\Users\\avidr\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: py4j in c:\\users\\avidr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.10.9.7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.2 -> 24.2\n",
            "[notice] To update, run: C:\\Users\\avidr\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# Check this site for the latest download link\n",
        "# https://www.apache.org/dyn/closer.lua/spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c8RNY4wS0iKl"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "  .master(\"local[*]\") \\\n",
        "  .appName(\"ITESO-2024-SparkIntroduction\") \\\n",
        "  .config(\"spark.driver.bindAddress\",\"localhost\") \\\n",
        "  .config(\"spark.ui.port\",\"4040\") \\\n",
        "  .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCFQkD7M0iKm",
        "outputId": "7fe1bad8-4b4a-4c0f-f822-2bd79a4dab84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Lorem', 'ipsum', 'dolor', 'sit', 'amet,', 'consectetur', 'adipiscing', 'elit.', 'Sed', 'do', 'eiusmod', 'tempor', 'incididunt', 'ut', 'labore', 'et', 'dolore', 'magna', 'aliqua.', 'Ut', 'enim', 'ad', 'minim', 'veniam,', 'quis', 'nostrud', 'exercitation', 'ullamco', 'laboris', 'nisi', 'ut', 'aliquip', 'ex', 'ea', 'commodo', 'consequat.', 'Duis', 'aute', 'irure', 'dolor', 'in', 'reprehenderit', 'in', 'voluptate', 'velit', 'esse', 'cillum', 'dolore', 'eu', 'fugiat', 'nulla', 'pariatur.', 'Excepteur', 'sint', 'occaecat', 'cupidatat', 'non', 'proident,', 'sunt', 'in', 'culpa', 'qui', 'officia', 'deserunt', 'mollit', 'anim', 'id', 'est', 'laborum.', 'Curabitur', 'pretium', 'tincidunt', 'lacus.', 'Nulla', 'gravida', 'orci', 'a', 'odio.', 'Nullam', 'varius,', 'turpis', 'et', 'commodo', 'pharetra,', 'est', 'eros', 'bibendum', 'elit,', 'nec', 'malesuada', 'elit', 'elit', 'vel', 'lectus.', 'Sed', 'ut', 'perspiciatis', 'unde', 'omnis', 'iste', 'natus', 'error', 'sit', 'voluptatem', 'accusantium', 'doloremque', 'laudantium.', 'Nemo', 'enim', 'ipsam', 'voluptatem', 'quia', 'voluptas', 'sit', 'aspernatur', 'aut', 'odit', 'aut', 'fugit.', 'Sed', 'quia', 'consequuntur', 'magni', 'dolores', 'eos', 'qui', 'ratione', 'voluptatem', 'sequi', 'nesciunt.', 'Neque', 'porro', 'quisquam', 'est', 'qui', 'dolorem', 'ipsum', 'quia', 'dolor', 'sit', 'amet,', 'consectetur,', 'adipisci', 'velit.', 'Lorem', 'ipsum', 'dolor', 'sit', 'amet,', 'consectetur', 'adipiscing', 'elit.', 'Sed', 'do', 'eiusmod', 'tempor', 'incididunt', 'ut', 'labore', 'et', 'dolore', 'magna', 'aliqua.', 'Ut', 'enim', 'ad', 'minim', 'veniam,', 'quis', 'nostrud', 'exercitation', 'ullamco', 'laboris', 'nisi', 'ut', 'aliquip', 'ex', 'ea', 'commodo', 'consequat.']\n"
          ]
        }
      ],
      "source": [
        "# Create an RDD with a list of sentences\n",
        "sentences = sentences = [\n",
        "    \"Lorem ipsum dolor sit amet, consectetur adipiscing elit.\",\n",
        "    \"Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n",
        "    \"Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\",\n",
        "    \"Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.\",\n",
        "    \"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\",\n",
        "    \"Curabitur pretium tincidunt lacus. Nulla gravida orci a odio.\",\n",
        "    \"Nullam varius, turpis et commodo pharetra, est eros bibendum elit, nec malesuada elit elit vel lectus.\",\n",
        "    \"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium.\",\n",
        "    \"Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\",\n",
        "    \"Sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.\",\n",
        "    \"Neque porro quisquam est qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit.\",\n",
        "    \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n",
        "    \"Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\"\n",
        "]\n",
        "sentences_rdd = sc.parallelize(sentences)\n",
        "\n",
        "# Tokenize the sentences into words\n",
        "words_rdd = sentences_rdd.flatMap(lambda line: line.split())\n",
        "\n",
        "print(words_rdd.collect())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOU3eBKy1XCh",
        "outputId": "cab1f8ae-d051-453f-c153-6408f373e393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('dolore', 3), ('aliqua.', 2), ('veniam,', 2), ('qui', 3), ('deserunt', 1), ('pretium', 1), ('Nulla', 1), ('odio.', 1), ('turpis', 1), ('nec', 1), ('error', 1), ('dolorem', 1), ('ipsum', 3), ('elit.', 2), ('tempor', 2), ('nostrud', 2), ('laboris', 2), ('occaecat', 1), ('cupidatat', 1), ('proident,', 1), ('culpa', 1), ('lacus.', 1), ('elit', 2), ('dolores', 1), ('dolor', 4), ('eiusmod', 2), ('Ut', 2), ('exercitation', 2), ('ullamco', 2), ('Duis', 1), ('esse', 1), ('vel', 1), ('doloremque', 1), ('Nemo', 1), ('do', 2), ('ex', 2), ('consequat.', 2), ('voluptate', 1), ('orci', 1), ('pharetra,', 1), ('voluptatem', 3), ('ipsam', 1), ('odit', 1), ('sequi', 1), ('velit.', 1), ('Lorem', 2), ('magna', 2), ('enim', 3), ('quis', 2), ('nulla', 1), ('anim', 1), ('tincidunt', 1), ('perspiciatis', 1), ('omnis', 1), ('eos', 1), ('sit', 5), ('eu', 1), ('Excepteur', 1), ('sunt', 1), ('mollit', 1), ('gravida', 1), ('elit,', 1), ('malesuada', 1), ('iste', 1), ('consequuntur', 1), ('magni', 1), ('Neque', 1), ('adipiscing', 2), ('et', 3), ('ea', 2), ('aute', 1), ('id', 1), ('est', 3), ('laborum.', 1), ('unde', 1), ('natus', 1), ('consectetur', 2), ('ad', 2), ('minim', 2), ('aliquip', 2), ('a', 1), ('Nullam', 1), ('laudantium.', 1), ('fugit.', 1), ('nesciunt.', 1), ('quisquam', 1), ('incididunt', 2), ('ut', 5), ('nisi', 2), ('irure', 1), ('cillum', 1), ('ratione', 1), ('consectetur,', 1), ('in', 3), ('pariatur.', 1), ('sint', 1), ('eros', 1), ('bibendum', 1), ('adipisci', 1), ('commodo', 3), ('velit', 1), ('fugiat', 1), ('non', 1), ('Curabitur', 1), ('lectus.', 1), ('aspernatur', 1), ('aut', 2), ('porro', 1), ('amet,', 3), ('Sed', 4), ('labore', 2), ('reprehenderit', 1), ('officia', 1), ('varius,', 1), ('accusantium', 1), ('quia', 3), ('voluptas', 1)]\n"
          ]
        }
      ],
      "source": [
        "# Compute the frequency of each word\n",
        "word_counts_rdd = words_rdd.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
        "print(word_counts_rdd.collect())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOvhnPL61g51",
        "outputId": "9aea2f68-7fc9-4546-9394-15395126b3cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most common word: [('sit', 5)]\n"
          ]
        }
      ],
      "source": [
        "# Find the most common word\n",
        "most_common_word = word_counts_rdd.takeOrdered(1, key=lambda x: -x[1])\n",
        "print(\"Most common word:\", most_common_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCIztSBe1nWp",
        "outputId": "1fc6e3fc-a3d8-4658-8493-e9876e08e9f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average word length: 5.605555555555555\n"
          ]
        }
      ],
      "source": [
        "# Compute the average word length\n",
        "total_length_rdd = words_rdd.map(lambda word: len(word)).reduce(lambda a, b: a + b)\n",
        "total_words = words_rdd.count()\n",
        "average_word_length = total_length_rdd / total_words if total_words > 0 else 0\n",
        "print(\"Average word length:\", average_word_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lab 01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reprehenderit\n"
          ]
        }
      ],
      "source": [
        "largests_words = words_rdd.sortBy(lambda x: len(x), ascending=False)\n",
        "largest_word = largests_words.take(1)[0]\n",
        "print(largest_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a\n"
          ]
        }
      ],
      "source": [
        "shortests_words = words_rdd.sortBy(lambda x: len(x))\n",
        "shortest_word = shortests_words.take(1)[0]\n",
        "print(shortest_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fmbP4gR_1p1q"
      },
      "outputs": [],
      "source": [
        "# Stop the SparkContext\n",
        "sc.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
