{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcamarillor/O2024_ESI3914O/blob/pablo_camarillo_add_spark_setup/examples/notebooks/lab01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPSQzDhW0nKI",
        "outputId": "6bfe432e-7678-42d6-8232-0a25c3496a2b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'sudo' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "The system cannot find the path specified.\n",
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "tar: Error opening archive: Failed to open 'spark-3.5.2-bin-hadoop3.tgz'\n",
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: C:\\Users\\Fernando\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in c:\\users\\fernando\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.5.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\fernando\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyspark) (0.10.9.7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: C:\\Users\\Fernando\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: py4j in c:\\users\\fernando\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.10.9.7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: C:\\Users\\Fernando\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# Check this site for the latest download link\n",
        "# https://www.apache.org/dyn/closer.lua/spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c8RNY4wS0iKl"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "  .master(\"local[*]\") \\\n",
        "  .appName(\"ITESO-2024-SparkIntroduction\") \\\n",
        "  .config(\"spark.driver.bindAddress\",\"localhost\") \\\n",
        "  .config(\"spark.ui.port\",\"4040\") \\\n",
        "  .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCFQkD7M0iKm",
        "outputId": "7fe1bad8-4b4a-4c0f-f822-2bd79a4dab84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Lorem', 'ipsum', 'dolor', 'sit', 'amet,', 'consectetur', 'adipiscing', 'elit.', 'Sed', 'do', 'eiusmod', 'tempor', 'incididunt', 'ut', 'labore', 'et', 'dolore', 'magna', 'aliqua.', 'Ut', 'enim', 'ad', 'minim', 'veniam,', 'quis', 'nostrud', 'exercitation', 'ullamco', 'laboris', 'nisi', 'ut', 'aliquip', 'ex', 'ea', 'commodo', 'consequat.', 'Duis', 'aute', 'irure', 'dolor', 'in', 'reprehenderit', 'in', 'voluptate', 'velit', 'esse', 'cillum', 'dolore', 'eu', 'fugiat', 'nulla', 'pariatur.', 'Excepteur', 'sint', 'occaecat', 'cupidatat', 'non', 'proident,', 'sunt', 'in', 'culpa', 'qui', 'officia', 'deserunt', 'mollit', 'anim', 'id', 'est', 'laborum.', 'Curabitur', 'pretium', 'tincidunt', 'lacus.', 'Nulla', 'gravida', 'orci', 'a', 'odio.', 'Nullam', 'varius,', 'turpis', 'et', 'commodo', 'pharetra,', 'est', 'eros', 'bibendum', 'elit,', 'nec', 'malesuada', 'elit', 'elit', 'vel', 'lectus.', 'Sed', 'ut', 'perspiciatis', 'unde', 'omnis', 'iste', 'natus', 'error', 'sit', 'voluptatem', 'accusantium', 'doloremque', 'laudantium.', 'Nemo', 'enim', 'ipsam', 'voluptatem', 'quia', 'voluptas', 'sit', 'aspernatur', 'aut', 'odit', 'aut', 'fugit.', 'Sed', 'quia', 'consequuntur', 'magni', 'dolores', 'eos', 'qui', 'ratione', 'voluptatem', 'sequi', 'nesciunt.', 'Neque', 'porro', 'quisquam', 'est', 'qui', 'dolorem', 'ipsum', 'quia', 'dolor', 'sit', 'amet,', 'consectetur,', 'adipisci', 'velit.', 'Lorem', 'ipsum', 'dolor', 'sit', 'amet,', 'consectetur', 'adipiscing', 'elit.', 'Sed', 'do', 'eiusmod', 'tempor', 'incididunt', 'ut', 'labore', 'et', 'dolore', 'magna', 'aliqua.', 'Ut', 'enim', 'ad', 'minim', 'veniam,', 'quis', 'nostrud', 'exercitation', 'ullamco', 'laboris', 'nisi', 'ut', 'aliquip', 'ex', 'ea', 'commodo', 'consequat.']\n"
          ]
        }
      ],
      "source": [
        "# Create an RDD with a list of sentences\n",
        "sentences = sentences = [\n",
        "    \"Lorem ipsum dolor sit amet, consectetur adipiscing elit.\",\n",
        "    \"Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n",
        "    \"Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\",\n",
        "    \"Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.\",\n",
        "    \"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\",\n",
        "    \"Curabitur pretium tincidunt lacus. Nulla gravida orci a odio.\",\n",
        "    \"Nullam varius, turpis et commodo pharetra, est eros bibendum elit, nec malesuada elit elit vel lectus.\",\n",
        "    \"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium.\",\n",
        "    \"Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\",\n",
        "    \"Sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.\",\n",
        "    \"Neque porro quisquam est qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit.\",\n",
        "    \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n",
        "    \"Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\"\n",
        "]\n",
        "sentences_rdd = sc.parallelize(sentences)\n",
        "\n",
        "# Tokenize the sentences into words\n",
        "words_rdd = sentences_rdd.flatMap(lambda line: line.split())\n",
        "\n",
        "print(words_rdd.collect())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOU3eBKy1XCh",
        "outputId": "cab1f8ae-d051-453f-c153-6408f373e393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('dolore', 3), ('veniam,', 2), ('ea', 2), ('deserunt', 1), ('Nulla', 1), ('odio.', 1), ('natus', 1), ('elit.', 2), ('tempor', 2), ('ad', 2), ('aliquip', 2), ('Nullam', 1), ('laudantium.', 1), ('incididunt', 2), ('ullamco', 2), ('esse', 1), ('consectetur,', 1), ('pariatur.', 1), ('pharetra,', 1), ('adipisci', 1), ('magna', 2), ('enim', 3), ('nulla', 1), ('lectus.', 1), ('perspiciatis', 1), ('eos', 1), ('porro', 1), ('sit', 5), ('reprehenderit', 1), ('Excepteur', 1), ('mollit', 1), ('quia', 3), ('adipiscing', 2), ('et', 3), ('aliqua.', 2), ('qui', 3), ('est', 3), ('turpis', 1), ('unde', 1), ('error', 1), ('dolorem', 1), ('consectetur', 2), ('minim', 2), ('laboris', 2), ('occaecat', 1), ('lacus.', 1), ('elit', 2), ('dolor', 4), ('irure', 1), ('vel', 1), ('doloremque', 1), ('in', 3), ('voluptate', 1), ('orci', 1), ('eros', 1), ('voluptatem', 3), ('ipsam', 1), ('sequi', 1), ('velit.', 1), ('quis', 2), ('commodo', 3), ('velit', 1), ('fugiat', 1), ('Curabitur', 1), ('tincidunt', 1), ('omnis', 1), ('labore', 2), ('eu', 1), ('sunt', 1), ('officia', 1), ('varius,', 1), ('elit,', 1), ('iste', 1), ('accusantium', 1), ('voluptas', 1), ('magni', 1), ('Neque', 1), ('aute', 1), ('id', 1), ('laborum.', 1), ('pretium', 1), ('nec', 1), ('ipsum', 3), ('nostrud', 2), ('cupidatat', 1), ('proident,', 1), ('culpa', 1), ('a', 1), ('fugit.', 1), ('dolores', 1), ('nesciunt.', 1), ('quisquam', 1), ('eiusmod', 2), ('ut', 5), ('Ut', 2), ('exercitation', 2), ('nisi', 2), ('Duis', 1), ('cillum', 1), ('Nemo', 1), ('ratione', 1), ('do', 2), ('ex', 2), ('consequat.', 2), ('sint', 1), ('bibendum', 1), ('odit', 1), ('Lorem', 2), ('non', 1), ('anim', 1), ('aspernatur', 1), ('aut', 2), ('amet,', 3), ('Sed', 4), ('gravida', 1), ('malesuada', 1), ('consequuntur', 1)]\n"
          ]
        }
      ],
      "source": [
        "# Compute the frequency of each word\n",
        "word_counts_rdd = words_rdd.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
        "print(word_counts_rdd.collect())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOvhnPL61g51",
        "outputId": "9aea2f68-7fc9-4546-9394-15395126b3cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most common word: [('sit', 5)]\n"
          ]
        }
      ],
      "source": [
        "# Find the most common word\n",
        "most_common_word = word_counts_rdd.takeOrdered(1, key=lambda x: -x[1])\n",
        "print(\"Most common word:\", most_common_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCIztSBe1nWp",
        "outputId": "1fc6e3fc-a3d8-4658-8493-e9876e08e9f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average word length: 5.605555555555555\n"
          ]
        }
      ],
      "source": [
        "# Compute the average word length\n",
        "total_length_rdd = words_rdd.map(lambda word: len(word)).reduce(lambda a, b: a + b)\n",
        "total_words = words_rdd.count()\n",
        "average_word_length = total_length_rdd / total_words if total_words > 0 else 0\n",
        "print(\"Average word length:\", average_word_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shortest word: ('a', 1)\n",
            "Longest word: ('reprehenderit', 13)\n"
          ]
        }
      ],
      "source": [
        "word_length_rdd = words_rdd.map(lambda word: (word, len(word)))\n",
        "\n",
        "# Words by length\n",
        "sorted_by_length_rdd = word_length_rdd.sortBy(lambda x: x[1])\n",
        "\n",
        "# Now we have the words sorted by length.\n",
        "# We can take the first element (shortest word)\n",
        "# and the last element (longest word)\n",
        "shortest_word = sorted_by_length_rdd.first()\n",
        "longest_word = sorted_by_length_rdd.takeOrdered(1, key=lambda x: -x[1])[0]\n",
        "\n",
        "print(\"Shortest word:\", shortest_word)\n",
        "print(\"Longest word:\", longest_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fmbP4gR_1p1q"
      },
      "outputs": [],
      "source": [
        "# Stop the SparkContext\n",
        "sc.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
