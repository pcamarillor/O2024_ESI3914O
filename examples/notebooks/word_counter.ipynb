{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcamarillor/O2024_ESI3914O/blob/pablo_camarillo_add_spark_setup/examples/notebooks/lab01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPSQzDhW0nKI",
        "outputId": "6bfe432e-7678-42d6-8232-0a25c3496a2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [1 InRelease 12.7 kB/129 kB 10%] [Connect\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Ign:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,240 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [53.3 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,559 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,498 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,425 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.7 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [81.4 kB]\n",
            "Fetched 15.3 MB in 2s (6,428 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "50 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=37f21fa8200d4d90b25ad5b7ea40ff0b493b7dad7d460da19cff0926a1af09cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# Check this site for the latest download link\n",
        "# https://www.apache.org/dyn/closer.lua/spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c8RNY4wS0iKl"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "  .master(\"local[*]\") \\\n",
        "  .appName(\"ITESO-2024-SparkIntroduction\") \\\n",
        "  .config(\"spark.driver.bindAddress\",\"localhost\") \\\n",
        "  .config(\"spark.ui.port\",\"4040\") \\\n",
        "  .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCFQkD7M0iKm",
        "outputId": "7fe1bad8-4b4a-4c0f-f822-2bd79a4dab84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Spark', 'is', 'a', 'unified', 'analytics', 'engine', 'It', 'provides', 'a', 'fast', 'and', 'general-purpose', 'cluster-computing', 'framework', 'RDDs', 'are', 'the', 'fundamental', 'data', 'structure', 'Spark', 'supports', 'many', 'languages', 'including', 'Python', 'and', 'Scala']\n"
          ]
        }
      ],
      "source": [
        "# Create an RDD with a list of sentences\n",
        "sentences = sentences = [\n",
        "    \"Lorem ipsum dolor sit amet, consectetur adipiscing elit.\",\n",
        "    \"Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n",
        "    \"Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\",\n",
        "    \"Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.\",\n",
        "    \"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\",\n",
        "    \"Curabitur pretium tincidunt lacus. Nulla gravida orci a odio.\",\n",
        "    \"Nullam varius, turpis et commodo pharetra, est eros bibendum elit, nec malesuada elit elit vel lectus.\",\n",
        "    \"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium.\",\n",
        "    \"Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\",\n",
        "    \"Sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.\",\n",
        "    \"Neque porro quisquam est qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit.\",\n",
        "    \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n",
        "    \"Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\"\n",
        "]\n",
        "sentences_rdd = sc.parallelize(sentences)\n",
        "\n",
        "# Tokenize the sentences into words\n",
        "words_rdd = sentences_rdd.flatMap(lambda line: line.split())\n",
        "\n",
        "print(words_rdd.collect())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOU3eBKy1XCh",
        "outputId": "cab1f8ae-d051-453f-c153-6408f373e393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Spark', 2), ('is', 1), ('unified', 1), ('analytics', 1), ('engine', 1), ('It', 1), ('provides', 1), ('general-purpose', 1), ('cluster-computing', 1), ('framework', 1), ('are', 1), ('fundamental', 1), ('supports', 1), ('Python', 1), ('a', 2), ('fast', 1), ('and', 2), ('RDDs', 1), ('the', 1), ('data', 1), ('structure', 1), ('many', 1), ('languages', 1), ('including', 1), ('Scala', 1)]\n"
          ]
        }
      ],
      "source": [
        "# Compute the frequency of each word\n",
        "word_counts_rdd = words_rdd.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
        "print(word_counts_rdd.collect())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOvhnPL61g51",
        "outputId": "9aea2f68-7fc9-4546-9394-15395126b3cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most common word: [('Spark', 2)]\n"
          ]
        }
      ],
      "source": [
        "# Find the most common word\n",
        "most_common_word = word_counts_rdd.takeOrdered(1, key=lambda x: -x[1])\n",
        "print(\"Most common word:\", most_common_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCIztSBe1nWp",
        "outputId": "1fc6e3fc-a3d8-4658-8493-e9876e08e9f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average word length: 6.142857142857143\n"
          ]
        }
      ],
      "source": [
        "# Compute the average word length\n",
        "total_length_rdd = words_rdd.map(lambda word: len(word)).reduce(lambda a, b: a + b)\n",
        "total_words = words_rdd.count()\n",
        "average_word_length = total_length_rdd / total_words if total_words > 0 else 0\n",
        "print(\"Average word length:\", average_word_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LUIS MIGUEL FONTES CARDONA LAB01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an RDD with a list of sentences\n",
        "sentences = sentences = [\n",
        "    \"Lorem ipsum dolor sit amet, consectetur adipiscing elit.\",\n",
        "    \"Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n",
        "    \"Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\",\n",
        "    \"Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.\",\n",
        "    \"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\",\n",
        "    \"Curabitur pretium tincidunt lacus. Nulla gravida orci a odio.\",\n",
        "    \"Nullam varius, turpis et commodo pharetra, est eros bibendum elit, nec malesuada elit elit vel lectus.\",\n",
        "    \"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium.\",\n",
        "    \"Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\",\n",
        "    \"Sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.\",\n",
        "    \"Neque porro quisquam est qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit.\",\n",
        "    \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n",
        "    \"Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\"\n",
        "]\n",
        "sentences_rdd = sc.parallelize(sentences)\n",
        "\n",
        "# Tokenize the sentences into words\n",
        "words_rdd = sentences_rdd.flatMap(lambda line: line.split())\n",
        "\n",
        "# Retrieve shortest word\n",
        "len_words = words_rdd.sortBy(lambda word: len(word)).first()\n",
        "\n",
        "print(len_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an RDD with a list of sentences\n",
        "sentences = sentences = [\n",
        "    \"Lorem ipsum dolor sit amet, consectetur adipiscing elit.\",\n",
        "    \"Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n",
        "    \"Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\",\n",
        "    \"Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.\",\n",
        "    \"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\",\n",
        "    \"Curabitur pretium tincidunt lacus. Nulla gravida orci a odio.\",\n",
        "    \"Nullam varius, turpis et commodo pharetra, est eros bibendum elit, nec malesuada elit elit vel lectus.\",\n",
        "    \"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium.\",\n",
        "    \"Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\",\n",
        "    \"Sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.\",\n",
        "    \"Neque porro quisquam est qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit.\",\n",
        "    \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n",
        "    \"Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\"\n",
        "]\n",
        "sentences_rdd = sc.parallelize(sentences)\n",
        "\n",
        "# Tokenize the sentences into words\n",
        "words_rdd = sentences_rdd.flatMap(lambda line: line.split())\n",
        "\n",
        "# Retrieve longest word\n",
        "len_words = words_rdd.sortBy(lambda word: len(word), ascending=False).first()\n",
        "\n",
        "print(len_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fmbP4gR_1p1q"
      },
      "outputs": [],
      "source": [
        "# Stop the SparkContext\n",
        "sc.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
