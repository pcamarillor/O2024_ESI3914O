{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "221a471b",
      "metadata": {
        "id": "221a471b"
      },
      "source": [
        "<div>\n",
        "<b><br><font face = \"Gill Sans\" size = \"4\"><center>Heart attack prediction with logistic regression</center></font></b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2Jh-BzcZuThT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Jh-BzcZuThT",
        "outputId": "269015d8-1a0e-48da-a183-b43502d72e6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "IOh1Ev_provA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOh1Ev_provA",
        "outputId": "14706f43-7ca3-4346-85e6-91e4fae8ed10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Ign:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,091 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,377 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,605 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.7 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,208 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,431 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [51.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,654 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,286 kB]\n",
            "Fetched 24.1 MB in 3s (7,473 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "53 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.5.2-bin-hadoop3.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# Check this site for the latest download link\n",
        "# https://www.apache.org/dyn/closer.lua/spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d75f58e4",
      "metadata": {
        "id": "d75f58e4"
      },
      "source": [
        "<span style=\"font-family:Gill Sans\">\n",
        "<h1>Hearth attach prediction with logisic regression</h1></span>\n",
        "\n",
        "Let us use PySpark to predict if a person can suffer a heart attack based on some medical information.\n",
        "\n",
        "Download the dataset from [Kaggle](https://www.kaggle.com/datasets/dileep070/heart-disease-prediction-using-logistic-regression?resource=download)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1b156f96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b156f96",
        "outputId": "e3fac373-a807-4d42-ed5d-5a7f00e1a3a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- male: integer (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- education: integer (nullable = true)\n",
            " |-- currentSmoker: integer (nullable = true)\n",
            " |-- cigsPerDay: integer (nullable = true)\n",
            " |-- BPMeds: integer (nullable = true)\n",
            " |-- prevalentStroke: integer (nullable = true)\n",
            " |-- prevalentHyp: integer (nullable = true)\n",
            " |-- diabetes: integer (nullable = true)\n",
            " |-- totChol: float (nullable = true)\n",
            " |-- sysBP: float (nullable = true)\n",
            " |-- diaBP: float (nullable = true)\n",
            " |-- BMI: float (nullable = true)\n",
            " |-- heartRate: integer (nullable = true)\n",
            " |-- glucose: integer (nullable = true)\n",
            " |-- TenYearCHD: integer (nullable = true)\n",
            "\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+-----+---------+-------+----------+\n",
            "|male|age|education|currentSmoker|cigsPerDay|BPMeds|prevalentStroke|prevalentHyp|diabetes|totChol|sysBP|diaBP|BMI  |heartRate|glucose|TenYearCHD|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+-----+---------+-------+----------+\n",
            "|1   |39 |4        |0            |0         |0     |0              |0           |0       |195.0  |106.0|70.0 |26.97|80       |77     |0         |\n",
            "|0   |46 |2        |0            |0         |0     |0              |0           |0       |250.0  |121.0|81.0 |28.73|95       |76     |0         |\n",
            "|1   |48 |1        |1            |20        |0     |0              |0           |0       |245.0  |127.5|80.0 |25.34|75       |70     |0         |\n",
            "|0   |61 |3        |1            |30        |0     |0              |1           |0       |225.0  |150.0|95.0 |28.58|65       |103    |1         |\n",
            "|0   |46 |3        |1            |23        |0     |0              |0           |0       |285.0  |130.0|84.0 |23.1 |85       |85     |0         |\n",
            "|0   |43 |2        |0            |0         |0     |0              |1           |0       |228.0  |180.0|110.0|30.3 |77       |99     |0         |\n",
            "|0   |63 |1        |0            |0         |0     |0              |0           |0       |205.0  |138.0|71.0 |33.11|60       |85     |1         |\n",
            "|0   |45 |2        |1            |20        |0     |0              |0           |0       |313.0  |100.0|71.0 |21.68|79       |78     |0         |\n",
            "|1   |52 |1        |0            |0         |0     |0              |1           |0       |260.0  |141.5|89.0 |26.36|76       |79     |0         |\n",
            "|1   |43 |1        |1            |30        |0     |0              |1           |0       |225.0  |162.0|107.0|23.61|93       |88     |0         |\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+-----+---------+-------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructField, StructType, FloatType, IntegerType\n",
        "\n",
        "# Create Spark Session in localhost\n",
        "spark = SparkSession.builder.master(\"local\").\\\n",
        "    appName(\"ITESO-LogisticRegression\").\\\n",
        "    getOrCreate()\n",
        "\n",
        "# Set spark context\n",
        "sc = spark.sparkContext\n",
        "sc.setLogLevel(\"ERROR\")\n",
        "\n",
        "heart_prediction_schema = StructType([\n",
        "    StructField(\"male\", IntegerType(), True),\n",
        "    StructField(\"age\", IntegerType(), True),\n",
        "    StructField(\"education\", IntegerType(), True),\n",
        "    StructField(\"currentSmoker\", IntegerType(), True),\n",
        "    StructField(\"cigsPerDay\", IntegerType(), True),\n",
        "    StructField(\"BPMeds\", IntegerType(), True),\n",
        "    StructField(\"prevalentStroke\", IntegerType(), True),\n",
        "    StructField(\"prevalentHyp\", IntegerType(), True),\n",
        "    StructField(\"diabetes\", IntegerType(), True),\n",
        "    StructField(\"totChol\", FloatType(), True),\n",
        "    StructField(\"sysBP\", FloatType(), True),\n",
        "    StructField(\"diaBP\", FloatType(), True),\n",
        "    StructField(\"BMI\", FloatType(), True),\n",
        "    StructField(\"heartRate\", IntegerType(), True),\n",
        "    StructField(\"glucose\", IntegerType(), True),\n",
        "    StructField(\"TenYearCHD\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "heart_df = spark.read.format(\"csv\").\\\n",
        "    option(\"header\", \"true\").\\\n",
        "    option(\"mode\", \"permissive\").\\\n",
        "    option(\"path\", \"/content/framingham.csv\").\\\n",
        "    schema(heart_prediction_schema).\\\n",
        "    load()\n",
        "heart_df.printSchema()\n",
        "heart_df.show(n=10, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "eeeefc3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeeefc3e",
        "outputId": "05ac5f7f-d7c6-4b49-a730-856d20fe0b64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "|male|age|education|currentSmoker|cigsPerDay|BPMeds|prevalentStroke|prevalentHyp|diabetes|totChol|sysBP|diaBP|BMI|heartRate|glucose|TenYearCHD|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "|   0|  0|      105|            0|        29|    53|              0|           0|       0|     50|    0|    0| 19|        1|    388|         0|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Find Count of Null, None, NaN of All DataFrame Columns\n",
        "from pyspark.sql.functions import col,isnan, when, count\n",
        "heart_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in heart_df.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8c777f97",
      "metadata": {
        "id": "8c777f97"
      },
      "outputs": [],
      "source": [
        "# Remove rows with at least one value as null\n",
        "\n",
        "heart_df = heart_df.dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a239282c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a239282c",
        "outputId": "e49f7a68-e2cb-491e-c01b-b06743eba19d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "|male|age|education|currentSmoker|cigsPerDay|BPMeds|prevalentStroke|prevalentHyp|diabetes|totChol|sysBP|diaBP|BMI|heartRate|glucose|TenYearCHD|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "|   0|  0|        0|            0|         0|     0|              0|           0|       0|      0|    0|    0|  0|        0|      0|         0|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "heart_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in heart_df.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LGohjy6p_ZG6"
      },
      "id": "LGohjy6p_ZG6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e30ee4a3",
      "metadata": {
        "id": "e30ee4a3"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.types import StructType, StructField, FloatType\n",
        "\n",
        "# Assemble the features into a single vector column\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "assembler = VectorAssembler(inputCols=[\n",
        "    \"male\", \"age\", \"education\", \"currentSmoker\", \"cigsPerDay\",\n",
        "    \"BPMeds\", \"prevalentStroke\", \"prevalentHyp\", \"diabetes\",\n",
        "    \"totChol\", \"sysBP\", \"diaBP\", \"BMI\", \"heartRate\",\n",
        "    \"glucose\"\n",
        "], outputCol=\"features\")\n",
        "\n",
        "data_with_features = assembler.transform(heart_df).select(\"TenYearCHD\", \"features\")\n",
        "\n",
        "# Split the data into training and test sets 70% training data and 30% testing data\n",
        "train, test = data_with_features.randomSplit([0.7, 0.3], seed=57)\n",
        "# Create a logistic regression model\n",
        "lr = LogisticRegression(maxIter=10, regParam=0.01, featuresCol=\"features\", labelCol=\"TenYearCHD\")\n",
        "# Train to get the mod\n",
        "lr_model = lr.fit(train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "4d71e840",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d71e840",
        "outputId": "e09e52af-6eba-48e3-911e-92ee18c749e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [0.5728581837020535,0.05735994205785407,-0.020296087562109176,0.07579602918356385,0.012702171657120023,0.3450321084063676,0.5434492327558711,0.24254325051377393,0.2482727165880535,0.0009956737523568449,0.014509428371414959,2.6048904178987696e-05,0.000821202641470393,-0.0022055738259466164,0.007571027389351979]\n",
            "+--------------------+----------+--------------------+\n",
            "|            features|prediction|         probability|\n",
            "+--------------------+----------+--------------------+\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97955921831705...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97353675648838...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97344272039882...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97758242748823...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.96966771953813...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.96757970201429...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97907527380872...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97829220533120...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.94994649877908...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.96748332874296...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97179673709563...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.96770672436260...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.95659828909861...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.96216319790027...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97563435642555...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.94961996835882...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.96579562066911...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.95759194680746...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.95812168561445...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.96262168833990...|\n",
            "+--------------------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print coefficients\n",
        "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = lr_model.transform(test)\n",
        "\n",
        "# Show predictions\n",
        "predictions.select(\"features\", \"prediction\", \"probability\").show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}