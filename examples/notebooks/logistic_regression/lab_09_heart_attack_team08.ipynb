{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1afb4593",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcamarillor/O2024_ESI3914O/blob/Lab09_team08/examples/notebooks/logistic_regression/heart_attack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "221a471b",
      "metadata": {
        "id": "221a471b"
      },
      "source": [
        "<div>\n",
        "<b><br><font face = \"Gill Sans\" size = \"4\"><center>Heart attack prediction with logistic regression</center></font></b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2Jh-BzcZuThT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Jh-BzcZuThT",
        "outputId": "cb8e257e-d9b1-42aa-e62c-0b98e3c3ea2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "IOh1Ev_provA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOh1Ev_provA",
        "outputId": "7cf28db3-d87e-4f51-b01b-1af42bcf1170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,091 kB]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Ign:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.7 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,208 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,605 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [51.8 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,286 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,377 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,654 kB]\n",
            "Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,431 kB]\n",
            "Fetched 24.1 MB in 5s (4,770 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "53 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.5.2-bin-hadoop3.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# Check this site for the latest download link\n",
        "# https://www.apache.org/dyn/closer.lua/spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d75f58e4",
      "metadata": {
        "id": "d75f58e4"
      },
      "source": [
        "<span style=\"font-family:Gill Sans\">\n",
        "<h1>Hearth attach prediction with logisic regression</h1></span>\n",
        "\n",
        "Let us use PySpark to predict if a person can suffer a heart attack based on some medical information.\n",
        "\n",
        "Download the dataset from [Kaggle](https://www.kaggle.com/datasets/dileep070/heart-disease-prediction-using-logistic-regression?resource=download)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1b156f96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b156f96",
        "outputId": "98d0a027-2d2c-4738-88ab-d4a43991c3bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- male: integer (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- education: integer (nullable = true)\n",
            " |-- currentSmoker: integer (nullable = true)\n",
            " |-- cigsPerDay: integer (nullable = true)\n",
            " |-- BPMeds: integer (nullable = true)\n",
            " |-- prevalentStroke: integer (nullable = true)\n",
            " |-- prevalentHyp: integer (nullable = true)\n",
            " |-- diabetes: integer (nullable = true)\n",
            " |-- totChol: float (nullable = true)\n",
            " |-- sysBP: float (nullable = true)\n",
            " |-- diaBP: float (nullable = true)\n",
            " |-- BMI: float (nullable = true)\n",
            " |-- heartRate: integer (nullable = true)\n",
            " |-- glucose: integer (nullable = true)\n",
            " |-- TenYearCHD: integer (nullable = true)\n",
            "\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+-----+---------+-------+----------+\n",
            "|male|age|education|currentSmoker|cigsPerDay|BPMeds|prevalentStroke|prevalentHyp|diabetes|totChol|sysBP|diaBP|BMI  |heartRate|glucose|TenYearCHD|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+-----+---------+-------+----------+\n",
            "|1   |39 |4        |0            |0         |0     |0              |0           |0       |195.0  |106.0|70.0 |26.97|80       |77     |0         |\n",
            "|0   |46 |2        |0            |0         |0     |0              |0           |0       |250.0  |121.0|81.0 |28.73|95       |76     |0         |\n",
            "|1   |48 |1        |1            |20        |0     |0              |0           |0       |245.0  |127.5|80.0 |25.34|75       |70     |0         |\n",
            "|0   |61 |3        |1            |30        |0     |0              |1           |0       |225.0  |150.0|95.0 |28.58|65       |103    |1         |\n",
            "|0   |46 |3        |1            |23        |0     |0              |0           |0       |285.0  |130.0|84.0 |23.1 |85       |85     |0         |\n",
            "|0   |43 |2        |0            |0         |0     |0              |1           |0       |228.0  |180.0|110.0|30.3 |77       |99     |0         |\n",
            "|0   |63 |1        |0            |0         |0     |0              |0           |0       |205.0  |138.0|71.0 |33.11|60       |85     |1         |\n",
            "|0   |45 |2        |1            |20        |0     |0              |0           |0       |313.0  |100.0|71.0 |21.68|79       |78     |0         |\n",
            "|1   |52 |1        |0            |0         |0     |0              |1           |0       |260.0  |141.5|89.0 |26.36|76       |79     |0         |\n",
            "|1   |43 |1        |1            |30        |0     |0              |1           |0       |225.0  |162.0|107.0|23.61|93       |88     |0         |\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+-----+---------+-------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructField, StructType, FloatType, IntegerType\n",
        "\n",
        "# Create Spark Session in localhost\n",
        "spark = SparkSession.builder.master(\"local\").\\\n",
        "    appName(\"ITESO-LogisticRegression\").\\\n",
        "    getOrCreate()\n",
        "\n",
        "# Set spark context\n",
        "sc = spark.sparkContext\n",
        "sc.setLogLevel(\"ERROR\")\n",
        "\n",
        "heart_prediction_schema = StructType([\n",
        "    StructField(\"male\", IntegerType(), True),\n",
        "    StructField(\"age\", IntegerType(), True),\n",
        "    StructField(\"education\", IntegerType(), True),\n",
        "    StructField(\"currentSmoker\", IntegerType(), True),\n",
        "    StructField(\"cigsPerDay\", IntegerType(), True),\n",
        "    StructField(\"BPMeds\", IntegerType(), True),\n",
        "    StructField(\"prevalentStroke\", IntegerType(), True),\n",
        "    StructField(\"prevalentHyp\", IntegerType(), True),\n",
        "    StructField(\"diabetes\", IntegerType(), True),\n",
        "    StructField(\"totChol\", FloatType(), True),\n",
        "    StructField(\"sysBP\", FloatType(), True),\n",
        "    StructField(\"diaBP\", FloatType(), True),\n",
        "    StructField(\"BMI\", FloatType(), True),\n",
        "    StructField(\"heartRate\", IntegerType(), True),\n",
        "    StructField(\"glucose\", IntegerType(), True),\n",
        "    StructField(\"TenYearCHD\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "heart_df = spark.read.format(\"csv\").\\\n",
        "    option(\"header\", \"true\").\\\n",
        "    option(\"mode\", \"permissive\").\\\n",
        "    option(\"path\", \"/content/drive/MyDrive/framingham.csv\").\\\n",
        "    schema(heart_prediction_schema).\\\n",
        "    load()\n",
        "heart_df.printSchema()\n",
        "heart_df.show(n=10, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eeeefc3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeeefc3e",
        "outputId": "7a01f309-9f5b-4dc8-cf07-88f433e2221b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "|male|age|education|currentSmoker|cigsPerDay|BPMeds|prevalentStroke|prevalentHyp|diabetes|totChol|sysBP|diaBP|BMI|heartRate|glucose|TenYearCHD|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "|   0|  0|      105|            0|        29|    53|              0|           0|       0|     50|    0|    0| 19|        1|    388|         0|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Find Count of Null, None, NaN of All DataFrame Columns\n",
        "from pyspark.sql.functions import col,isnan, when, count\n",
        "heart_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in heart_df.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8c777f97",
      "metadata": {
        "id": "8c777f97"
      },
      "outputs": [],
      "source": [
        "# Remove rows with at least one value as null\n",
        "heart_df = heart_df.na.drop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a239282c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a239282c",
        "outputId": "ad559bc0-6df7-4065-d1ce-5034b733022a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "|male|age|education|currentSmoker|cigsPerDay|BPMeds|prevalentStroke|prevalentHyp|diabetes|totChol|sysBP|diaBP|BMI|heartRate|glucose|TenYearCHD|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "|   0|  0|        0|            0|         0|     0|              0|           0|       0|      0|    0|    0|  0|        0|      0|         0|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "heart_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in heart_df.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e30ee4a3",
      "metadata": {
        "id": "e30ee4a3"
      },
      "outputs": [],
      "source": [
        "# Assemble the features into a single vector column\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "feature_columns = [\n",
        "    \"male\", \"age\", \"education\", \"currentSmoker\", \"cigsPerDay\",\n",
        "    \"BPMeds\", \"prevalentStroke\", \"prevalentHyp\", \"diabetes\",\n",
        "    \"totChol\", \"sysBP\", \"diaBP\", \"BMI\", \"heartRate\", \"glucose\"\n",
        "]\n",
        "\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "heart_df_assembled = assembler.transform(heart_df)\n",
        "\n",
        "\n",
        "# Split the data into training and test sets (70% training, 30% testing)\n",
        "train_data, test_data = heart_df_assembled.randomSplit([0.7, 0.3], seed=7) #seven for CR7 SIUUUU, LOL !\n",
        "\n",
        "# Create a logistic regression model\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "logistic_reg = LogisticRegression(featuresCol=\"features\", labelCol=\"TenYearCHD\")\n",
        "\n",
        "# Train the model\n",
        "model = logistic_reg.fit(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4d71e840",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d71e840",
        "outputId": "d0c1898a-e8d5-45c1-c4b9-41da8b952dd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coefficients:  [0.4328329133762021,0.0679613939327408,-0.07141385788499359,0.11088233152787885,0.01852747096545094,0.2125822141329982,0.9686289667032562,0.15371871078282723,0.1618647372607062,0.0022228403239372705,0.013686193056669837,-0.004149831554988723,0.014695384028554703,-0.0016930612867964337,0.005012343776575037]\n",
            "Intercept:  -8.309921578003303\n",
            "+-------------------------------------------------------------------------------------+----------+----------+\n",
            "|features                                                                             |TenYearCHD|prediction|\n",
            "+-------------------------------------------------------------------------------------+----------+----------+\n",
            "|[0.0,33.0,2.0,1.0,5.0,0.0,0.0,0.0,0.0,200.0,119.0,74.0,23.799999237060547,75.0,74.0] |0         |0.0       |\n",
            "|(15,[1,2,9,10,11,12,13,14],[34.0,2.0,170.0,121.0,74.0,20.81999969482422,67.0,83.0])  |0         |0.0       |\n",
            "|(15,[1,2,9,10,11,12,13,14],[34.0,2.0,226.0,112.5,77.5,24.989999771118164,100.0,72.0])|0         |0.0       |\n",
            "|[0.0,34.0,2.0,1.0,20.0,0.0,0.0,0.0,0.0,180.0,111.0,56.0,21.510000228881836,91.0,78.0]|0         |0.0       |\n",
            "|[0.0,34.0,2.0,1.0,20.0,0.0,0.0,0.0,0.0,220.0,117.5,67.5,20.790000915527344,63.0,86.0]|0         |0.0       |\n",
            "|(15,[1,2,9,10,11,12,13,14],[34.0,3.0,227.0,102.0,68.0,24.959999084472656,80.0,75.0]) |0         |0.0       |\n",
            "|(15,[1,2,9,10,11,12,13,14],[35.0,1.0,170.0,110.0,69.0,23.479999542236328,75.0,83.0]) |0         |0.0       |\n",
            "|(15,[1,2,9,10,11,12,13,14],[35.0,2.0,165.0,117.5,72.5,27.860000610351562,63.0,67.0]) |0         |0.0       |\n",
            "|(15,[1,2,9,10,11,12,13,14],[35.0,2.0,175.0,121.5,74.5,20.860000610351562,92.0,93.0]) |0         |0.0       |\n",
            "|(15,[1,2,9,10,11,12,13,14],[35.0,2.0,248.0,107.0,73.0,20.639999389648438,90.0,80.0]) |0         |0.0       |\n",
            "|[0.0,35.0,2.0,1.0,1.0,0.0,0.0,0.0,0.0,194.0,100.5,69.0,17.920000076293945,75.0,73.0] |0         |0.0       |\n",
            "|[0.0,35.0,2.0,1.0,5.0,0.0,0.0,0.0,0.0,165.0,106.0,64.0,19.139999389648438,68.0,70.0] |0         |0.0       |\n",
            "|[0.0,35.0,2.0,1.0,5.0,0.0,0.0,0.0,0.0,186.0,106.0,78.0,24.729999542236328,60.0,70.0] |0         |0.0       |\n",
            "|[0.0,35.0,2.0,1.0,20.0,0.0,0.0,0.0,0.0,231.0,150.0,90.0,23.09000015258789,83.0,72.0] |0         |0.0       |\n",
            "|[0.0,35.0,2.0,1.0,30.0,0.0,0.0,0.0,0.0,245.0,148.0,84.0,23.739999771118164,60.0,73.0]|0         |0.0       |\n",
            "|(15,[1,2,9,10,11,12,13,14],[36.0,1.0,165.0,115.0,71.0,21.270000457763672,64.0,86.0]) |0         |0.0       |\n",
            "|(15,[1,2,9,10,11,12,13,14],[36.0,1.0,180.0,116.0,85.5,26.31999969482422,95.0,81.0])  |0         |0.0       |\n",
            "|(15,[1,2,9,10,11,12,13,14],[36.0,1.0,200.0,108.0,62.0,20.790000915527344,75.0,69.0]) |0         |0.0       |\n",
            "|[0.0,36.0,1.0,1.0,5.0,0.0,0.0,1.0,0.0,222.0,147.0,94.0,26.790000915527344,76.0,71.0] |0         |0.0       |\n",
            "|[0.0,36.0,1.0,1.0,15.0,0.0,0.0,0.0,0.0,178.0,102.5,65.0,20.8700008392334,75.0,94.0]  |0         |0.0       |\n",
            "+-------------------------------------------------------------------------------------+----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print coefficients\n",
        "print(\"Coefficients: \", model.coefficients)\n",
        "print(\"Intercept: \", model.intercept)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Show the predictions\n",
        "predictions.select(\"features\", \"TenYearCHD\", \"prediction\").show(truncate=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
