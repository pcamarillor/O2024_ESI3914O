{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "221a471b",
      "metadata": {
        "id": "221a471b"
      },
      "source": [
        "<div>\n",
        "<b><br><font face = \"Gill Sans\" size = \"4\"><center>Heart attack prediction with logistic regression</center></font></b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2Jh-BzcZuThT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "2Jh-BzcZuThT",
        "outputId": "32817a75-140a-4d9a-8fb7-edee8fcd86a1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "IOh1Ev_provA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOh1Ev_provA",
        "outputId": "5c0fbb4a-c08e-4636-869f-dd2e05139831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.81)] [\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\u001b[33m\r0% [2 InRelease 33.0 kB/128 kB 26%] [Connecting to security.ubuntu.com (185.125\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connected\u001b[0m\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "\u001b[33m\r0% [3 InRelease 15.6 kB/127 kB 12%] [Waiting for headers] [Waiting for headers]\u001b[0m\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [3 InRelease 59.1 kB/127 kB 46%] [Waiting for headers] [4 InRelease 3,626 B/\u001b[0m\u001b[33m\r0% [3 InRelease 67.6 kB/127 kB 53%] [Waiting for headers] [Waiting for headers]\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connected\u001b[0m\r                                                                               \rGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Ign:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,286 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [51.8 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,654 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,091 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,605 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,431 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.7 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,208 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,377 kB]\n",
            "Fetched 24.1 MB in 4s (6,570 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "53 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.5.2-bin-hadoop3.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# Check this site for the latest download link\n",
        "# https://www.apache.org/dyn/closer.lua/spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d75f58e4",
      "metadata": {
        "id": "d75f58e4"
      },
      "source": [
        "<span style=\"font-family:Gill Sans\">\n",
        "<h1>Hearth attach prediction with logisic regression</h1></span>\n",
        "\n",
        "Let us use PySpark to predict if a person can suffer a heart attack based on some medical information.\n",
        "\n",
        "Download the dataset from [Kaggle](https://www.kaggle.com/datasets/dileep070/heart-disease-prediction-using-logistic-regression?resource=download)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1b156f96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b156f96",
        "outputId": "7b606ddd-4003-4258-8275-c832468e3528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- male: integer (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- education: integer (nullable = true)\n",
            " |-- currentSmoker: integer (nullable = true)\n",
            " |-- cigsPerDay: integer (nullable = true)\n",
            " |-- BPMeds: integer (nullable = true)\n",
            " |-- prevalentStroke: integer (nullable = true)\n",
            " |-- prevalentHyp: integer (nullable = true)\n",
            " |-- diabetes: integer (nullable = true)\n",
            " |-- totChol: float (nullable = true)\n",
            " |-- sysBP: float (nullable = true)\n",
            " |-- diaBP: float (nullable = true)\n",
            " |-- BMI: float (nullable = true)\n",
            " |-- heartRate: integer (nullable = true)\n",
            " |-- glucose: integer (nullable = true)\n",
            " |-- TenYearCHD: integer (nullable = true)\n",
            "\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+-----+---------+-------+----------+\n",
            "|male|age|education|currentSmoker|cigsPerDay|BPMeds|prevalentStroke|prevalentHyp|diabetes|totChol|sysBP|diaBP|BMI  |heartRate|glucose|TenYearCHD|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+-----+---------+-------+----------+\n",
            "|1   |39 |4        |0            |0         |0     |0              |0           |0       |195.0  |106.0|70.0 |26.97|80       |77     |0         |\n",
            "|0   |46 |2        |0            |0         |0     |0              |0           |0       |250.0  |121.0|81.0 |28.73|95       |76     |0         |\n",
            "|1   |48 |1        |1            |20        |0     |0              |0           |0       |245.0  |127.5|80.0 |25.34|75       |70     |0         |\n",
            "|0   |61 |3        |1            |30        |0     |0              |1           |0       |225.0  |150.0|95.0 |28.58|65       |103    |1         |\n",
            "|0   |46 |3        |1            |23        |0     |0              |0           |0       |285.0  |130.0|84.0 |23.1 |85       |85     |0         |\n",
            "|0   |43 |2        |0            |0         |0     |0              |1           |0       |228.0  |180.0|110.0|30.3 |77       |99     |0         |\n",
            "|0   |63 |1        |0            |0         |0     |0              |0           |0       |205.0  |138.0|71.0 |33.11|60       |85     |1         |\n",
            "|0   |45 |2        |1            |20        |0     |0              |0           |0       |313.0  |100.0|71.0 |21.68|79       |78     |0         |\n",
            "|1   |52 |1        |0            |0         |0     |0              |1           |0       |260.0  |141.5|89.0 |26.36|76       |79     |0         |\n",
            "|1   |43 |1        |1            |30        |0     |0              |1           |0       |225.0  |162.0|107.0|23.61|93       |88     |0         |\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+-----+---------+-------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructField, StructType, FloatType, IntegerType\n",
        "\n",
        "# Create Spark Session in localhost\n",
        "spark = SparkSession.builder.master(\"local\").\\\n",
        "    appName(\"ITESO-LogisticRegression\").\\\n",
        "    getOrCreate()\n",
        "\n",
        "# Set spark context\n",
        "sc = spark.sparkContext\n",
        "sc.setLogLevel(\"ERROR\")\n",
        "\n",
        "heart_prediction_schema = StructType([\n",
        "    StructField(\"male\", IntegerType(), True),\n",
        "    StructField(\"age\", IntegerType(), True),\n",
        "    StructField(\"education\", IntegerType(), True),\n",
        "    StructField(\"currentSmoker\", IntegerType(), True),\n",
        "    StructField(\"cigsPerDay\", IntegerType(), True),\n",
        "    StructField(\"BPMeds\", IntegerType(), True),\n",
        "    StructField(\"prevalentStroke\", IntegerType(), True),\n",
        "    StructField(\"prevalentHyp\", IntegerType(), True),\n",
        "    StructField(\"diabetes\", IntegerType(), True),\n",
        "    StructField(\"totChol\", FloatType(), True),\n",
        "    StructField(\"sysBP\", FloatType(), True),\n",
        "    StructField(\"diaBP\", FloatType(), True),\n",
        "    StructField(\"BMI\", FloatType(), True),\n",
        "    StructField(\"heartRate\", IntegerType(), True),\n",
        "    StructField(\"glucose\", IntegerType(), True),\n",
        "    StructField(\"TenYearCHD\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "heart_df = spark.read.format(\"csv\").\\\n",
        "    option(\"header\", \"true\").\\\n",
        "    option(\"mode\", \"permissive\").\\\n",
        "    option(\"path\", \"/content/sample_data/framingham.csv\").\\\n",
        "    schema(heart_prediction_schema).\\\n",
        "    load()\n",
        "heart_df.printSchema()\n",
        "heart_df.show(n=10, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "eeeefc3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeeefc3e",
        "outputId": "5cf1ca3c-d101-4932-b4ac-b549fd779840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "|male|age|education|currentSmoker|cigsPerDay|BPMeds|prevalentStroke|prevalentHyp|diabetes|totChol|sysBP|diaBP|BMI|heartRate|glucose|TenYearCHD|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "|   0|  0|      105|            0|        29|    53|              0|           0|       0|     50|    0|    0| 19|        1|    388|         0|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Find Count of Null, None, NaN of All DataFrame Columns\n",
        "from pyspark.sql.functions import col,isnan, when, count\n",
        "heart_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in heart_df.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8c777f97",
      "metadata": {
        "id": "8c777f97"
      },
      "outputs": [],
      "source": [
        "# Remove rows with at least one value as null\n",
        "heart_df = heart_df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a239282c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a239282c",
        "outputId": "aa6b5292-d6cb-4bc5-8f31-bd2aac962411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "|male|age|education|currentSmoker|cigsPerDay|BPMeds|prevalentStroke|prevalentHyp|diabetes|totChol|sysBP|diaBP|BMI|heartRate|glucose|TenYearCHD|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "|   0|  0|        0|            0|         0|     0|              0|           0|       0|      0|    0|    0|  0|        0|      0|         0|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "heart_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in heart_df.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "e30ee4a3",
      "metadata": {
        "id": "e30ee4a3"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Rename the label column to \"label\"\n",
        "heart_df = heart_df.withColumnRenamed(\"TenYearCHD\", \"label\")\n",
        "\n",
        "# Assemble the features into a single vector column\n",
        "assembler = VectorAssembler(inputCols=[\n",
        "    \"male\", \"age\", \"education\", \"currentSmoker\", \"cigsPerDay\", \"BPMeds\",\n",
        "    \"prevalentStroke\", \"prevalentHyp\", \"diabetes\", \"totChol\", \"sysBP\",\n",
        "    \"diaBP\", \"BMI\", \"heartRate\", \"glucose\"\n",
        "], outputCol=\"features\")\n",
        "\n",
        "# Transform the data to include the features column\n",
        "data_with_features = assembler.transform(heart_df).select(\"label\", \"features\")\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train_data, test_data = data_with_features.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Create and fit the logistic regression model\n",
        "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
        "lr_model = lr.fit(train_data)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = lr_model.transform(test_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "4d71e840",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d71e840",
        "outputId": "52e73716-375d-45aa-8033-2df774de3bc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients:  [0.4735396025580804,0.06041851836266556,-0.03971877928307416,0.2327369515049285,0.011143608436434018,0.4403698648334802,0.9518941968506953,0.17819944273141272,-0.0599048894289396,0.001665153192667679,0.012546906571086345,0.003169244721366329,0.006568041721294876,-0.0017887287753067774,0.00761459674519659]\n",
            "Intercept:  -8.3516206112187\n",
            "+-----+----------+-----------------------------------------+\n",
            "|label|prediction|probability                              |\n",
            "+-----+----------+-----------------------------------------+\n",
            "|0    |0.0       |[0.9787648567524393,0.021235143247560706]|\n",
            "|0    |0.0       |[0.9768582477203768,0.02314175227962323] |\n",
            "|0    |0.0       |[0.977182692308456,0.022817307691543998] |\n",
            "|0    |0.0       |[0.9818163357412204,0.018183664258779597]|\n",
            "|0    |0.0       |[0.9769288665751202,0.023071133424879764]|\n",
            "|0    |0.0       |[0.976143718517526,0.023856281482473984] |\n",
            "|0    |0.0       |[0.9775945400869978,0.022405459913002246]|\n",
            "|0    |0.0       |[0.9782016359655559,0.02179836403444413] |\n",
            "|0    |0.0       |[0.9785645259549869,0.021435474045013114]|\n",
            "|0    |0.0       |[0.9774453488109859,0.02255465118901412] |\n",
            "|0    |0.0       |[0.9768683597087402,0.023131640291259803]|\n",
            "|0    |0.0       |[0.976777523433717,0.023222476566282957] |\n",
            "|0    |0.0       |[0.9716168974791831,0.028383102520816883]|\n",
            "|0    |0.0       |[0.9675989601160484,0.0324010398839516]  |\n",
            "|0    |0.0       |[0.9681399849027231,0.03186001509727687] |\n",
            "|0    |0.0       |[0.9636849847043908,0.03631501529560921] |\n",
            "|0    |0.0       |[0.9700908931634894,0.0299091068365106]  |\n",
            "|0    |0.0       |[0.9704494409190767,0.0295505590809233]  |\n",
            "|0    |0.0       |[0.9773834719196006,0.02261652808039938] |\n",
            "|0    |0.0       |[0.980537918481791,0.01946208151820905]  |\n",
            "+-----+----------+-----------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print coefficients\n",
        "print(\"Coefficients: \", lr_model.coefficients)\n",
        "print(\"Intercept: \", lr_model.intercept)\n",
        "# Make predictions on the test set\n",
        "predictions = lr_model.transform(test_data)\n",
        "\n",
        "# Show predictions with label, prediction, and probability\n",
        "predictions.select(\"label\", \"prediction\", \"probability\").show(20, truncate=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
