{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcamarillor/O2024_ESI3914O/blob/team5_lab09_model/heart_attack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "221a471b",
      "metadata": {
        "id": "221a471b"
      },
      "source": [
        "<div>\n",
        "<b><br><font face = \"Gill Sans\" size = \"4\"><center>Heart attack prediction with logistic regression</center></font></b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2Jh-BzcZuThT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Jh-BzcZuThT",
        "outputId": "cf4a496c-11cb-4005-c62a-c6edc23e56a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IOh1Ev_provA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOh1Ev_provA",
        "outputId": "eddb14dc-ef5c-4f42-de3e-4d86dad1269f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Ign:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,091 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,431 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,208 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,654 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,377 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.7 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,605 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [51.8 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,286 kB]\n",
            "Fetched 24.1 MB in 5s (5,309 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "53 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.5.2-bin-hadoop3.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# Check this site for the latest download link\n",
        "# https://www.apache.org/dyn/closer.lua/spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d75f58e4",
      "metadata": {
        "id": "d75f58e4"
      },
      "source": [
        "<span style=\"font-family:Gill Sans\">\n",
        "<h1>Hearth attach prediction with logisic regression</h1></span>\n",
        "\n",
        "Let us use PySpark to predict if a person can suffer a heart attack based on some medical information.\n",
        "\n",
        "Download the dataset from [Kaggle](https://www.kaggle.com/datasets/dileep070/heart-disease-prediction-using-logistic-regression?resource=download)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b156f96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b156f96",
        "outputId": "f35ff601-86e3-4845-8c06-83ecbcbfbf19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- male: integer (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- education: integer (nullable = true)\n",
            " |-- currentSmoker: integer (nullable = true)\n",
            " |-- cigsPerDay: integer (nullable = true)\n",
            " |-- BPMeds: integer (nullable = true)\n",
            " |-- prevalentStroke: integer (nullable = true)\n",
            " |-- prevalentHyp: integer (nullable = true)\n",
            " |-- diabetes: integer (nullable = true)\n",
            " |-- totChol: float (nullable = true)\n",
            " |-- sysBP: float (nullable = true)\n",
            " |-- diaBP: float (nullable = true)\n",
            " |-- BMI: float (nullable = true)\n",
            " |-- heartRate: integer (nullable = true)\n",
            " |-- glucose: integer (nullable = true)\n",
            " |-- TenYearCHD: integer (nullable = true)\n",
            "\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+-----+---------+-------+----------+\n",
            "|male|age|education|currentSmoker|cigsPerDay|BPMeds|prevalentStroke|prevalentHyp|diabetes|totChol|sysBP|diaBP|BMI  |heartRate|glucose|TenYearCHD|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+-----+---------+-------+----------+\n",
            "|1   |39 |4        |0            |0         |0     |0              |0           |0       |195.0  |106.0|70.0 |26.97|80       |77     |0         |\n",
            "|0   |46 |2        |0            |0         |0     |0              |0           |0       |250.0  |121.0|81.0 |28.73|95       |76     |0         |\n",
            "|1   |48 |1        |1            |20        |0     |0              |0           |0       |245.0  |127.5|80.0 |25.34|75       |70     |0         |\n",
            "|0   |61 |3        |1            |30        |0     |0              |1           |0       |225.0  |150.0|95.0 |28.58|65       |103    |1         |\n",
            "|0   |46 |3        |1            |23        |0     |0              |0           |0       |285.0  |130.0|84.0 |23.1 |85       |85     |0         |\n",
            "|0   |43 |2        |0            |0         |0     |0              |1           |0       |228.0  |180.0|110.0|30.3 |77       |99     |0         |\n",
            "|0   |63 |1        |0            |0         |0     |0              |0           |0       |205.0  |138.0|71.0 |33.11|60       |85     |1         |\n",
            "|0   |45 |2        |1            |20        |0     |0              |0           |0       |313.0  |100.0|71.0 |21.68|79       |78     |0         |\n",
            "|1   |52 |1        |0            |0         |0     |0              |1           |0       |260.0  |141.5|89.0 |26.36|76       |79     |0         |\n",
            "|1   |43 |1        |1            |30        |0     |0              |1           |0       |225.0  |162.0|107.0|23.61|93       |88     |0         |\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+-----+---------+-------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructField, StructType, FloatType, IntegerType\n",
        "\n",
        "# Create Spark Session in localhost\n",
        "spark = SparkSession.builder.master(\"local\").\\\n",
        "    appName(\"ITESO-LogisticRegression\").\\\n",
        "    getOrCreate()\n",
        "\n",
        "# Set spark context\n",
        "sc = spark.sparkContext\n",
        "sc.setLogLevel(\"ERROR\")\n",
        "\n",
        "heart_prediction_schema = StructType([\n",
        "    StructField(\"male\", IntegerType(), True),\n",
        "    StructField(\"age\", IntegerType(), True),\n",
        "    StructField(\"education\", IntegerType(), True),\n",
        "    StructField(\"currentSmoker\", IntegerType(), True),\n",
        "    StructField(\"cigsPerDay\", IntegerType(), True),\n",
        "    StructField(\"BPMeds\", IntegerType(), True),\n",
        "    StructField(\"prevalentStroke\", IntegerType(), True),\n",
        "    StructField(\"prevalentHyp\", IntegerType(), True),\n",
        "    StructField(\"diabetes\", IntegerType(), True),\n",
        "    StructField(\"totChol\", FloatType(), True),\n",
        "    StructField(\"sysBP\", FloatType(), True),\n",
        "    StructField(\"diaBP\", FloatType(), True),\n",
        "    StructField(\"BMI\", FloatType(), True),\n",
        "    StructField(\"heartRate\", IntegerType(), True),\n",
        "    StructField(\"glucose\", IntegerType(), True),\n",
        "    StructField(\"TenYearCHD\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "heart_df = spark.read.format(\"csv\").\\\n",
        "    option(\"header\", \"true\").\\\n",
        "    option(\"mode\", \"permissive\").\\\n",
        "    option(\"path\", \"/content/framingham.csv\").\\\n",
        "    schema(heart_prediction_schema).\\\n",
        "    load()\n",
        "heart_df.printSchema()\n",
        "heart_df.show(n=10, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeeefc3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeeefc3e",
        "outputId": "2fa1a114-2296-4a49-8df0-7d34b085606e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "|male|age|education|currentSmoker|cigsPerDay|BPMeds|prevalentStroke|prevalentHyp|diabetes|totChol|sysBP|diaBP|BMI|heartRate|glucose|TenYearCHD|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "|   0|  0|      105|            0|        29|    53|              0|           0|       0|     50|    0|    0| 19|        1|    388|         0|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Find Count of Null, None, NaN of All DataFrame Columns\n",
        "from pyspark.sql.functions import col,isnan, when, count\n",
        "heart_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in heart_df.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c777f97",
      "metadata": {
        "id": "8c777f97"
      },
      "outputs": [],
      "source": [
        "# Remove rows with at least one value as null\n",
        "heart_df = heart_df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a239282c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a239282c",
        "outputId": "6e0013f2-8736-446d-9773-0a110060a0fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "|male|age|education|currentSmoker|cigsPerDay|BPMeds|prevalentStroke|prevalentHyp|diabetes|totChol|sysBP|diaBP|BMI|heartRate|glucose|TenYearCHD|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "|   0|  0|        0|            0|         0|     0|              0|           0|       0|      0|    0|    0|  0|        0|      0|         0|\n",
            "+----+---+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+---+---------+-------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "heart_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in heart_df.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e30ee4a3",
      "metadata": {
        "id": "e30ee4a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ada33b02-efe0-454c-e99a-89201f9b6758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+\n",
            "|TenYearCHD|            features|\n",
            "+----------+--------------------+\n",
            "|         0|(15,[1,2,9,10,11,...|\n",
            "|         0|(15,[1,2,9,10,11,...|\n",
            "|         0|(15,[1,2,9,10,11,...|\n",
            "|         0|(15,[1,2,9,10,11,...|\n",
            "|         0|(15,[1,2,9,10,11,...|\n",
            "+----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+--------------------+\n",
            "|TenYearCHD|            features|\n",
            "+----------+--------------------+\n",
            "|         0|(15,[1,2,9,10,11,...|\n",
            "|         0|(15,[1,2,9,10,11,...|\n",
            "|         0|(15,[1,2,9,10,11,...|\n",
            "|         0|(15,[1,2,9,10,11,...|\n",
            "|         0|(15,[1,2,9,10,11,...|\n",
            "+----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Assemble the features into a single vector column\n",
        "assembler = VectorAssembler(inputCols=[\"male\",\"age\",\"education\",\"currentSmoker\",\"cigsPerDay\",\"BPMeds\",\"prevalentStroke\",\"prevalentHyp\",\"diabetes\",\"totChol\",\"sysBP\",\"diaBP\",\"BMI\",\"heartRate\",\"glucose\"], outputCol=\"features\")\n",
        "data_with_features = assembler.transform(heart_df).select(\"TenYearCHD\", \"features\")\n",
        "\n",
        "#data_with_features.show(n=5)\n",
        "# Split the data into training and test sets 70% training data and 30% testing data\n",
        "train, test = data_with_features.randomSplit([0.7, 0.3], seed=57)\n",
        "\n",
        "train.show(n=5)\n",
        "test.show(n=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "# Create a logistic regression model\n",
        "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"TenYearCHD\")\n",
        "\n",
        "# Train to get the model\n",
        "lr_model = lr.fit(train)"
      ],
      "metadata": {
        "id": "Ei6-PUY3Boae"
      },
      "id": "Ei6-PUY3Boae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d71e840",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d71e840",
        "outputId": "9f965964-a971-471b-e0cc-32bc1039aa07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [0.6378773480532327,0.062395508152567634,-0.012446089746229677,0.0562932799243091,0.014740607924864091,0.32964839757063386,0.576104308672386,0.2126224654121739,0.19174996969202535,0.0009492877303977642,0.017508810698592142,-0.0036997324537733313,0.001362093080941249,-0.00226359081418126,0.008170615824907128]\n",
            "+--------------------+----------+--------------------+\n",
            "|            features|prediction|         probability|\n",
            "+--------------------+----------+--------------------+\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.98254785867922...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97722045111776...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97796036917776...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.98092929414614...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97350378227493...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97110978611260...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.98173207239612...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.98092996529309...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.95229725542918...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97074881682183...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97655832174986...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97072708660473...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.96106782051891...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.96674317044878...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97901952769262...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.95403424200171...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.97128491633756...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.96296271568868...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.96234005467665...|\n",
            "|(15,[1,2,9,10,11,...|       0.0|[0.96652295830028...|\n",
            "+--------------------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print coefficients\n",
        "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
        "\n",
        "# Display model summary\n",
        "training_summary = lr_model.summary\n",
        "\n",
        "# Make predictions on the test set\n",
        "\n",
        "# Use the trained model to make predictions on the test data\n",
        "predictions = lr_model.transform(test)\n",
        "\n",
        "# Show predictions\n",
        "predictions.select(\"features\", \"prediction\", \"probability\").show()\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}