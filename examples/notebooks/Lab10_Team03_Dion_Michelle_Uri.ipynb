{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHLyBUR2IYDD",
        "outputId": "cbe65c80-9383-49f3-eb3e-9110546ae7d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-01 00:30:53--  https://raw.githubusercontent.com/selva86/datasets/master/Iris.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5107 (5.0K) [text/plain]\n",
            "Saving to: ‘Iris.csv’\n",
            "\n",
            "\rIris.csv              0%[                    ]       0  --.-KB/s               \rIris.csv            100%[===================>]   4.99K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-01 00:30:53 (49.3 MB/s) - ‘Iris.csv’ saved [5107/5107]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O Iris.csv https://raw.githubusercontent.com/selva86/datasets/master/Iris.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Luse1ClGIeuk",
        "outputId": "2889e550-92e7-46e8-8b44-e3408d7f48fb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv Iris.csv /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "id": "uk1E8tdMIrzZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n"
      ],
      "metadata": {
        "id": "snrQ-QXMIzyJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"IrisDecisionTree\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "5cRGYtQ5I0jS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = spark.read.csv(\"/content/drive/MyDrive/Iris.csv\", header=True, inferSchema=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "vpO6_Yk5I3sq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=[\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"], outputCol=\"features\")\n",
        "data_with_features = assembler.transform(data).select(\"Species\", \"features\")\n",
        "\n",
        "\n",
        "train, test = data_with_features.randomSplit([0.8, 0.2], seed=42)\n"
      ],
      "metadata": {
        "id": "kCzD1XYyI5ld"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"Species\", outputCol=\"label\")\n",
        "data_with_labels = indexer.fit(data_with_features).transform(data_with_features)\n",
        "\n"
      ],
      "metadata": {
        "id": "Gw_JFrWxI8Ov"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = data_with_labels.randomSplit([0.8, 0.2], seed=42)\n",
        "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "model = dt.fit(train)"
      ],
      "metadata": {
        "id": "4XP-RvicLMBZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test)"
      ],
      "metadata": {
        "id": "eTmddtRnLVTV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "\n",
        "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
        "print(f\"Precision: {precision}\")\n",
        "\n",
        "\n",
        "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
        "print(f\"Recall: {recall}\")\n",
        "\n",
        "\n",
        "f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NmHtLHZLWHw",
        "outputId": "ab2a8a4c-cc31-4d22-fe6b-db6871715e5a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9166666666666666\n",
            "Precision: 0.9166666666666666\n",
            "Recall: 0.9166666666666666\n",
            "F1 Score: 0.9166666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "K8BEFisBI8q0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}